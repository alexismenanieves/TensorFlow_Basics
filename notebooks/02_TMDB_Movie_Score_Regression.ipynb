{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **TMDB Score Prediction** - Regression with deep learning\n",
    "- **Date**: Mar 6, 2024  \n",
    "- **Task**: Create a model to predict movie score based on text and numeric inputs \n",
    "- **Procedure**: Analyze data with pandas, create nn model in TensorFlow\n",
    "- **Dataset source**: https://www.kaggle.com/datasets/columbine/imdb-dataset-sentiment-analysis-in-csv-format/data   \n",
    "- **References**: https://github.com/PhilChodrow/PIC16B/blob/7d12d32e070e7ff3840b971c0ce4185ef1911796/discussion/tmdb.ipynb#L758"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 0. Load libraries and custom functions\n",
    "# Matrices and datasets ------------------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Graphics -------------------------------------------------------------\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Text processors\n",
    "import re\n",
    "import string\n",
    "#import nltk\n",
    "#from nltk.corpus import stopwords\n",
    "#nltk.download('stopwords')\n",
    "from wordcloud import WordCloud\n",
    "# Machine Learning -----------------------------------------------------\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# Deep Learning --------------------------------------------------------\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from keras.layers import TextVectorization\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4803 entries, 0 to 4802\n",
      "Data columns (total 20 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   budget                4803 non-null   int64  \n",
      " 1   genres                4803 non-null   object \n",
      " 2   homepage              1712 non-null   object \n",
      " 3   id                    4803 non-null   int64  \n",
      " 4   keywords              4803 non-null   object \n",
      " 5   original_language     4803 non-null   object \n",
      " 6   original_title        4803 non-null   object \n",
      " 7   overview              4800 non-null   object \n",
      " 8   popularity            4803 non-null   float64\n",
      " 9   production_companies  4803 non-null   object \n",
      " 10  production_countries  4803 non-null   object \n",
      " 11  release_date          4802 non-null   object \n",
      " 12  revenue               4803 non-null   int64  \n",
      " 13  runtime               4801 non-null   float64\n",
      " 14  spoken_languages      4803 non-null   object \n",
      " 15  status                4803 non-null   object \n",
      " 16  tagline               3959 non-null   object \n",
      " 17  title                 4803 non-null   object \n",
      " 18  vote_average          4803 non-null   float64\n",
      " 19  vote_count            4803 non-null   int64  \n",
      "dtypes: float64(3), int64(4), object(13)\n",
      "memory usage: 750.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# Step 1. Load data\n",
    "# 1.1 Read csv and get basic info\n",
    "df_raw = pd.read_csv('../data/02_TMDB_5000_movies.csv')\n",
    "df_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>id</th>\n",
       "      <th>keywords</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>production_companies</th>\n",
       "      <th>production_countries</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2182</th>\n",
       "      <td>0</td>\n",
       "      <td>[{\"id\": 16, \"name\": \"Animation\"}, {\"id\": 10751...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13682</td>\n",
       "      <td>[]</td>\n",
       "      <td>en</td>\n",
       "      <td>Pooh's Heffalump Movie</td>\n",
       "      <td>Who or what exactly is a Heffalump? The lovabl...</td>\n",
       "      <td>9.031540</td>\n",
       "      <td>[{\"name\": \"Walt Disney Pictures\", \"id\": 2}]</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2005-02-11</td>\n",
       "      <td>0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>There's something new in the Hundred Acre Wood.</td>\n",
       "      <td>Pooh's Heffalump Movie</td>\n",
       "      <td>6.4</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3274</th>\n",
       "      <td>8000000</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 53, \"nam...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13154</td>\n",
       "      <td>[{\"id\": 1794, \"name\": \"yakuza\"}, {\"id\": 12670,...</td>\n",
       "      <td>en</td>\n",
       "      <td>Showdown in Little Tokyo</td>\n",
       "      <td>An American with a Japanese upbringing, Chris ...</td>\n",
       "      <td>8.403859</td>\n",
       "      <td>[{\"name\": \"Original Pictures\", \"id\": 4234}, {\"...</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>1991-08-23</td>\n",
       "      <td>2275557</td>\n",
       "      <td>79.0</td>\n",
       "      <td>[{\"iso_639_1\": \"ja\", \"name\": \"\\u65e5\\u672c\\u8a...</td>\n",
       "      <td>Released</td>\n",
       "      <td>One's a warrior. One's a wise guy. They're two...</td>\n",
       "      <td>Showdown in Little Tokyo</td>\n",
       "      <td>5.7</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>49000000</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 35, \"nam...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9548</td>\n",
       "      <td>[{\"id\": 578, \"name\": \"rock and roll\"}, {\"id\": ...</td>\n",
       "      <td>en</td>\n",
       "      <td>The Adventures of Ford Fairlane</td>\n",
       "      <td>Ford \"Mr. Rock n' Roll Detective\" Fairlane is ...</td>\n",
       "      <td>2.808428</td>\n",
       "      <td>[{\"name\": \"Twentieth Century Fox Film Corporat...</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>1990-07-11</td>\n",
       "      <td>20423389</td>\n",
       "      <td>104.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Kojak. Columbo. Dirty Harry. Wimps.</td>\n",
       "      <td>The Adventures of Ford Fairlane</td>\n",
       "      <td>6.2</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1383</th>\n",
       "      <td>32000000</td>\n",
       "      <td>[{\"id\": 18, \"name\": \"Drama\"}]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13920</td>\n",
       "      <td>[{\"id\": 5565, \"name\": \"biography\"}, {\"id\": 605...</td>\n",
       "      <td>en</td>\n",
       "      <td>Radio</td>\n",
       "      <td>High school football coach, Harold Jones befri...</td>\n",
       "      <td>9.254647</td>\n",
       "      <td>[{\"name\": \"Revolution Studios\", \"id\": 497}, {\"...</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2003-10-24</td>\n",
       "      <td>52277485</td>\n",
       "      <td>109.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>His courage made them champions.</td>\n",
       "      <td>Radio</td>\n",
       "      <td>6.8</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2724</th>\n",
       "      <td>18339750</td>\n",
       "      <td>[{\"id\": 18, \"name\": \"Drama\"}, {\"id\": 36, \"name...</td>\n",
       "      <td>http://www.downfallthefilm.com/</td>\n",
       "      <td>613</td>\n",
       "      <td>[{\"id\": 220, \"name\": \"berlin\"}, {\"id\": 351, \"n...</td>\n",
       "      <td>de</td>\n",
       "      <td>Der Untergang</td>\n",
       "      <td>In April of 1945, Germany stands at the brink ...</td>\n",
       "      <td>32.445895</td>\n",
       "      <td>[{\"name\": \"Degeto Film\", \"id\": 986}, {\"name\": ...</td>\n",
       "      <td>[{\"iso_3166_1\": \"AT\", \"name\": \"Austria\"}, {\"is...</td>\n",
       "      <td>2004-09-08</td>\n",
       "      <td>92180910</td>\n",
       "      <td>156.0</td>\n",
       "      <td>[{\"iso_639_1\": \"hu\", \"name\": \"Magyar\"}, {\"iso_...</td>\n",
       "      <td>Released</td>\n",
       "      <td>April 1945, a nation awaits its...Downfall</td>\n",
       "      <td>Downfall</td>\n",
       "      <td>7.7</td>\n",
       "      <td>1037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3340</th>\n",
       "      <td>7000000</td>\n",
       "      <td>[{\"id\": 18, \"name\": \"Drama\"}, {\"id\": 10749, \"n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>713</td>\n",
       "      <td>[{\"id\": 128, \"name\": \"love triangle\"}, {\"id\": ...</td>\n",
       "      <td>en</td>\n",
       "      <td>The Piano</td>\n",
       "      <td>After a long voyage from Scotland, pianist Ada...</td>\n",
       "      <td>17.681707</td>\n",
       "      <td>[{\"name\": \"New South Wales Film &amp; Television O...</td>\n",
       "      <td>[{\"iso_3166_1\": \"NZ\", \"name\": \"New Zealand\"}, ...</td>\n",
       "      <td>1993-05-19</td>\n",
       "      <td>116700000</td>\n",
       "      <td>121.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}, {\"iso...</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Piano</td>\n",
       "      <td>7.1</td>\n",
       "      <td>281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>0</td>\n",
       "      <td>[{\"id\": 10749, \"name\": \"Romance\"}, {\"id\": 18, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>161795</td>\n",
       "      <td>[{\"id\": 9673, \"name\": \"love\"}, {\"id\": 14638, \"...</td>\n",
       "      <td>en</td>\n",
       "      <td>Déjà Vu</td>\n",
       "      <td>L.A. shop owner Dana and Englishman Sean meet ...</td>\n",
       "      <td>0.605645</td>\n",
       "      <td>[{\"name\": \"Rainbow Film Company, The\", \"id\": 2...</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>1998-04-22</td>\n",
       "      <td>0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Your future is set...</td>\n",
       "      <td>Déjà Vu</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4168</th>\n",
       "      <td>0</td>\n",
       "      <td>[{\"id\": 18, \"name\": \"Drama\"}, {\"id\": 53, \"name...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>356987</td>\n",
       "      <td>[{\"id\": 230912, \"name\": \"supervivencia\"}]</td>\n",
       "      <td>en</td>\n",
       "      <td>Abandoned</td>\n",
       "      <td>When their yacht capsizes during a storm; four...</td>\n",
       "      <td>3.068463</td>\n",
       "      <td>[{\"name\": \"Making Movies\", \"id\": 71702}]</td>\n",
       "      <td>[{\"iso_3166_1\": \"NZ\", \"name\": \"New Zealand\"}]</td>\n",
       "      <td>2015-08-30</td>\n",
       "      <td>0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abandoned</td>\n",
       "      <td>5.8</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4057</th>\n",
       "      <td>2160000</td>\n",
       "      <td>[{\"id\": 18, \"name\": \"Drama\"}]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43610</td>\n",
       "      <td>[]</td>\n",
       "      <td>en</td>\n",
       "      <td>The Valley of Decision</td>\n",
       "      <td>Mary Rafferty comes from a poor family of stee...</td>\n",
       "      <td>0.181300</td>\n",
       "      <td>[{\"name\": \"Metro-Goldwyn-Mayer (MGM)\", \"id\": 8...</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>1945-06-01</td>\n",
       "      <td>9132000</td>\n",
       "      <td>119.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Valley of Decision</td>\n",
       "      <td>5.8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4456</th>\n",
       "      <td>800000</td>\n",
       "      <td>[{\"id\": 18, \"name\": \"Drama\"}, {\"id\": 10749, \"n...</td>\n",
       "      <td>http://www.lhp.com.sg/victor/</td>\n",
       "      <td>25461</td>\n",
       "      <td>[{\"id\": 10183, \"name\": \"independent film\"}]</td>\n",
       "      <td>en</td>\n",
       "      <td>Raising Victor Vargas</td>\n",
       "      <td>The film follows Victor, a Lower East Side tee...</td>\n",
       "      <td>3.643662</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2002-05-16</td>\n",
       "      <td>2816116</td>\n",
       "      <td>88.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}, {\"iso...</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Raising Victor Vargas</td>\n",
       "      <td>7.8</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        budget                                             genres  \\\n",
       "2182         0  [{\"id\": 16, \"name\": \"Animation\"}, {\"id\": 10751...   \n",
       "3274   8000000  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 53, \"nam...   \n",
       "1003  49000000  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 35, \"nam...   \n",
       "1383  32000000                      [{\"id\": 18, \"name\": \"Drama\"}]   \n",
       "2724  18339750  [{\"id\": 18, \"name\": \"Drama\"}, {\"id\": 36, \"name...   \n",
       "3340   7000000  [{\"id\": 18, \"name\": \"Drama\"}, {\"id\": 10749, \"n...   \n",
       "463          0  [{\"id\": 10749, \"name\": \"Romance\"}, {\"id\": 18, ...   \n",
       "4168         0  [{\"id\": 18, \"name\": \"Drama\"}, {\"id\": 53, \"name...   \n",
       "4057   2160000                      [{\"id\": 18, \"name\": \"Drama\"}]   \n",
       "4456    800000  [{\"id\": 18, \"name\": \"Drama\"}, {\"id\": 10749, \"n...   \n",
       "\n",
       "                             homepage      id  \\\n",
       "2182                              NaN   13682   \n",
       "3274                              NaN   13154   \n",
       "1003                              NaN    9548   \n",
       "1383                              NaN   13920   \n",
       "2724  http://www.downfallthefilm.com/     613   \n",
       "3340                              NaN     713   \n",
       "463                               NaN  161795   \n",
       "4168                              NaN  356987   \n",
       "4057                              NaN   43610   \n",
       "4456    http://www.lhp.com.sg/victor/   25461   \n",
       "\n",
       "                                               keywords original_language  \\\n",
       "2182                                                 []                en   \n",
       "3274  [{\"id\": 1794, \"name\": \"yakuza\"}, {\"id\": 12670,...                en   \n",
       "1003  [{\"id\": 578, \"name\": \"rock and roll\"}, {\"id\": ...                en   \n",
       "1383  [{\"id\": 5565, \"name\": \"biography\"}, {\"id\": 605...                en   \n",
       "2724  [{\"id\": 220, \"name\": \"berlin\"}, {\"id\": 351, \"n...                de   \n",
       "3340  [{\"id\": 128, \"name\": \"love triangle\"}, {\"id\": ...                en   \n",
       "463   [{\"id\": 9673, \"name\": \"love\"}, {\"id\": 14638, \"...                en   \n",
       "4168          [{\"id\": 230912, \"name\": \"supervivencia\"}]                en   \n",
       "4057                                                 []                en   \n",
       "4456        [{\"id\": 10183, \"name\": \"independent film\"}]                en   \n",
       "\n",
       "                       original_title  \\\n",
       "2182           Pooh's Heffalump Movie   \n",
       "3274         Showdown in Little Tokyo   \n",
       "1003  The Adventures of Ford Fairlane   \n",
       "1383                            Radio   \n",
       "2724                    Der Untergang   \n",
       "3340                        The Piano   \n",
       "463                           Déjà Vu   \n",
       "4168                        Abandoned   \n",
       "4057           The Valley of Decision   \n",
       "4456            Raising Victor Vargas   \n",
       "\n",
       "                                               overview  popularity  \\\n",
       "2182  Who or what exactly is a Heffalump? The lovabl...    9.031540   \n",
       "3274  An American with a Japanese upbringing, Chris ...    8.403859   \n",
       "1003  Ford \"Mr. Rock n' Roll Detective\" Fairlane is ...    2.808428   \n",
       "1383  High school football coach, Harold Jones befri...    9.254647   \n",
       "2724  In April of 1945, Germany stands at the brink ...   32.445895   \n",
       "3340  After a long voyage from Scotland, pianist Ada...   17.681707   \n",
       "463   L.A. shop owner Dana and Englishman Sean meet ...    0.605645   \n",
       "4168  When their yacht capsizes during a storm; four...    3.068463   \n",
       "4057  Mary Rafferty comes from a poor family of stee...    0.181300   \n",
       "4456  The film follows Victor, a Lower East Side tee...    3.643662   \n",
       "\n",
       "                                   production_companies  \\\n",
       "2182        [{\"name\": \"Walt Disney Pictures\", \"id\": 2}]   \n",
       "3274  [{\"name\": \"Original Pictures\", \"id\": 4234}, {\"...   \n",
       "1003  [{\"name\": \"Twentieth Century Fox Film Corporat...   \n",
       "1383  [{\"name\": \"Revolution Studios\", \"id\": 497}, {\"...   \n",
       "2724  [{\"name\": \"Degeto Film\", \"id\": 986}, {\"name\": ...   \n",
       "3340  [{\"name\": \"New South Wales Film & Television O...   \n",
       "463   [{\"name\": \"Rainbow Film Company, The\", \"id\": 2...   \n",
       "4168           [{\"name\": \"Making Movies\", \"id\": 71702}]   \n",
       "4057  [{\"name\": \"Metro-Goldwyn-Mayer (MGM)\", \"id\": 8...   \n",
       "4456                                                 []   \n",
       "\n",
       "                                   production_countries release_date  \\\n",
       "2182  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2005-02-11   \n",
       "3274  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   1991-08-23   \n",
       "1003  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   1990-07-11   \n",
       "1383  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2003-10-24   \n",
       "2724  [{\"iso_3166_1\": \"AT\", \"name\": \"Austria\"}, {\"is...   2004-09-08   \n",
       "3340  [{\"iso_3166_1\": \"NZ\", \"name\": \"New Zealand\"}, ...   1993-05-19   \n",
       "463   [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   1998-04-22   \n",
       "4168      [{\"iso_3166_1\": \"NZ\", \"name\": \"New Zealand\"}]   2015-08-30   \n",
       "4057  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   1945-06-01   \n",
       "4456  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2002-05-16   \n",
       "\n",
       "        revenue  runtime                                   spoken_languages  \\\n",
       "2182          0     68.0           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]   \n",
       "3274    2275557     79.0  [{\"iso_639_1\": \"ja\", \"name\": \"\\u65e5\\u672c\\u8a...   \n",
       "1003   20423389    104.0           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]   \n",
       "1383   52277485    109.0           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]   \n",
       "2724   92180910    156.0  [{\"iso_639_1\": \"hu\", \"name\": \"Magyar\"}, {\"iso_...   \n",
       "3340  116700000    121.0  [{\"iso_639_1\": \"en\", \"name\": \"English\"}, {\"iso...   \n",
       "463           0    117.0           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]   \n",
       "4168          0     82.0           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]   \n",
       "4057    9132000    119.0           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]   \n",
       "4456    2816116     88.0  [{\"iso_639_1\": \"en\", \"name\": \"English\"}, {\"iso...   \n",
       "\n",
       "        status                                            tagline  \\\n",
       "2182  Released    There's something new in the Hundred Acre Wood.   \n",
       "3274  Released  One's a warrior. One's a wise guy. They're two...   \n",
       "1003  Released                Kojak. Columbo. Dirty Harry. Wimps.   \n",
       "1383  Released                   His courage made them champions.   \n",
       "2724  Released         April 1945, a nation awaits its...Downfall   \n",
       "3340  Released                                                NaN   \n",
       "463   Released                              Your future is set...   \n",
       "4168  Released                                                NaN   \n",
       "4057  Released                                                NaN   \n",
       "4456  Released                                                NaN   \n",
       "\n",
       "                                title  vote_average  vote_count  \n",
       "2182           Pooh's Heffalump Movie           6.4          88  \n",
       "3274         Showdown in Little Tokyo           5.7          95  \n",
       "1003  The Adventures of Ford Fairlane           6.2          71  \n",
       "1383                            Radio           6.8         141  \n",
       "2724                         Downfall           7.7        1037  \n",
       "3340                        The Piano           7.1         281  \n",
       "463                           Déjà Vu           8.0           1  \n",
       "4168                        Abandoned           5.8          27  \n",
       "4057           The Valley of Decision           5.8           4  \n",
       "4456            Raising Victor Vargas           7.8          13  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.2 Get a sample\n",
    "df_raw.sample(10, random_state=2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the columns contains nested json data, other contains unique \n",
    "information like ids or names, so let's transform our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Preprocess data\n",
    "# 2.1 Create a interim dataset for transformations, drop unused columns and NAs\n",
    "df_interim = df_raw.copy()\n",
    "df_interim = df_interim.drop(columns=['id','original_title','title','vote_count','original_language','homepage'])\n",
    "df_interim = df_interim.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can concatenate each id value in json format to form a id collection\n",
    "and process it for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 Concatenate strings in json format and drop changed columns\n",
    "df_interim['genres_c'] = df_interim['genres'].apply(lambda x: ' '.join([str(y['id']) for y in eval(x)]))\n",
    "df_interim['keywords_c'] = df_interim['keywords'].apply(lambda x: ' '.join([str(y['id']) for y in eval(x)]))\n",
    "df_interim['producers_c'] = df_interim['production_companies'].apply(lambda x: ' '.join([str(y['id']) for y in eval(x)]))\n",
    "df_interim['countries_c'] = df_interim['production_countries'].apply(lambda x: ' '.join([str(y['iso_3166_1']) for y in eval(x)]))\n",
    "df_interim['languages_c'] = df_interim['spoken_languages'].apply(lambda x: ' '.join([str(y['iso_639_1']) for y in eval(x)]))\n",
    "df_interim = df_interim.drop(columns=['genres','keywords','production_companies','production_countries','spoken_languages'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>budget</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>genres_c</th>\n",
       "      <th>keywords_c</th>\n",
       "      <th>producers_c</th>\n",
       "      <th>countries_c</th>\n",
       "      <th>languages_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3384</th>\n",
       "      <td>7000000</td>\n",
       "      <td>The lives of three women have a commonality: a...</td>\n",
       "      <td>5.517597</td>\n",
       "      <td>2009-11-07</td>\n",
       "      <td>0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.7</td>\n",
       "      <td>18 10749</td>\n",
       "      <td>8018 9838 10707</td>\n",
       "      <td>1092 10892</td>\n",
       "      <td>ES US</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1766</th>\n",
       "      <td>27000000</td>\n",
       "      <td>In her many years as a social worker, Emily Je...</td>\n",
       "      <td>23.917982</td>\n",
       "      <td>2009-08-13</td>\n",
       "      <td>29000000</td>\n",
       "      <td>109.0</td>\n",
       "      <td>Released</td>\n",
       "      <td>Some cases should  never be opened.</td>\n",
       "      <td>6.1</td>\n",
       "      <td>27 9648 53</td>\n",
       "      <td>516 703 2438 6152 9826 11857 14751 14819 15017...</td>\n",
       "      <td>838 10039 11581 11582</td>\n",
       "      <td>CA US</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        budget                                           overview  popularity  \\\n",
       "3384   7000000  The lives of three women have a commonality: a...    5.517597   \n",
       "1766  27000000  In her many years as a social worker, Emily Je...   23.917982   \n",
       "\n",
       "     release_date   revenue  runtime    status  \\\n",
       "3384   2009-11-07         0    125.0  Released   \n",
       "1766   2009-08-13  29000000    109.0  Released   \n",
       "\n",
       "                                  tagline  vote_average    genres_c  \\\n",
       "3384                                  NaN           6.7    18 10749   \n",
       "1766  Some cases should  never be opened.           6.1  27 9648 53   \n",
       "\n",
       "                                             keywords_c  \\\n",
       "3384                                    8018 9838 10707   \n",
       "1766  516 703 2438 6152 9826 11857 14751 14819 15017...   \n",
       "\n",
       "                producers_c countries_c languages_c  \n",
       "3384             1092 10892       ES US          en  \n",
       "1766  838 10039 11581 11582       CA US          en  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4803, 14)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.3 View results and current shape\n",
    "display(df_interim.sample(2))\n",
    "df_interim.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now some information comes as numeric like budget. But since values in \n",
    "budgets are quite large, we can apply some transformations like log. To \n",
    "avoid zeros, we can add 1 to all values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.4 Transform scale in numeric variables\n",
    "df_interim['budget_log'] = np.log(df_interim['budget']+1)\n",
    "df_interim['revenue_log'] = np.log(df_interim['revenue']+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About the date, we can use a point of reference, like the year of the \n",
    "oldest movie as starting point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.5 Transform the date\n",
    "df_interim['Year_t'] = df_interim['release_date'].apply(lambda x: float(str(x)[0:4]) if (str(x)[0:4])!='' else 2000)\n",
    "df_interim['Month_t'] = df_interim['release_date'].apply(lambda x: float(str(x)[5:7]) if (str(x)[5:7])!='' else 1)\n",
    "df_interim = df_interim.drop(columns=['release_date'])\n",
    "df_interim['Year_diff'] = df_interim['Year_t'] - min(df_interim['Year_t'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we create our final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>runtime</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>genres_c</th>\n",
       "      <th>keywords_c</th>\n",
       "      <th>producers_c</th>\n",
       "      <th>countries_c</th>\n",
       "      <th>languages_c</th>\n",
       "      <th>budget_log</th>\n",
       "      <th>revenue_log</th>\n",
       "      <th>Year_t</th>\n",
       "      <th>Month_t</th>\n",
       "      <th>Year_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2182</th>\n",
       "      <td>Who or what exactly is a Heffalump? The lovabl...</td>\n",
       "      <td>9.031540</td>\n",
       "      <td>68.0</td>\n",
       "      <td>Released</td>\n",
       "      <td>There's something new in the Hundred Acre Wood.</td>\n",
       "      <td>6.4</td>\n",
       "      <td>16 10751</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>US</td>\n",
       "      <td>en</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>89.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3274</th>\n",
       "      <td>An American with a Japanese upbringing, Chris ...</td>\n",
       "      <td>8.403859</td>\n",
       "      <td>79.0</td>\n",
       "      <td>Released</td>\n",
       "      <td>One's a warrior. One's a wise guy. They're two...</td>\n",
       "      <td>5.7</td>\n",
       "      <td>28 53</td>\n",
       "      <td>1794 12670 18098</td>\n",
       "      <td>4234 6194</td>\n",
       "      <td>US</td>\n",
       "      <td>ja en</td>\n",
       "      <td>15.894952</td>\n",
       "      <td>14.637736</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>Ford \"Mr. Rock n' Roll Detective\" Fairlane is ...</td>\n",
       "      <td>2.808428</td>\n",
       "      <td>104.0</td>\n",
       "      <td>Released</td>\n",
       "      <td>Kojak. Columbo. Dirty Harry. Wimps.</td>\n",
       "      <td>6.2</td>\n",
       "      <td>28 35 53 80 9648</td>\n",
       "      <td>578 837 2570 5540 9826 155790</td>\n",
       "      <td>306 1885</td>\n",
       "      <td>US</td>\n",
       "      <td>en</td>\n",
       "      <td>17.707331</td>\n",
       "      <td>16.832191</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               overview  popularity  runtime  \\\n",
       "2182  Who or what exactly is a Heffalump? The lovabl...    9.031540     68.0   \n",
       "3274  An American with a Japanese upbringing, Chris ...    8.403859     79.0   \n",
       "1003  Ford \"Mr. Rock n' Roll Detective\" Fairlane is ...    2.808428    104.0   \n",
       "\n",
       "        status                                            tagline  \\\n",
       "2182  Released    There's something new in the Hundred Acre Wood.   \n",
       "3274  Released  One's a warrior. One's a wise guy. They're two...   \n",
       "1003  Released                Kojak. Columbo. Dirty Harry. Wimps.   \n",
       "\n",
       "      vote_average          genres_c                     keywords_c  \\\n",
       "2182           6.4          16 10751                                  \n",
       "3274           5.7             28 53               1794 12670 18098   \n",
       "1003           6.2  28 35 53 80 9648  578 837 2570 5540 9826 155790   \n",
       "\n",
       "     producers_c countries_c languages_c  budget_log  revenue_log  Year_t  \\\n",
       "2182           2          US          en    0.000000     0.000000  2005.0   \n",
       "3274   4234 6194          US       ja en   15.894952    14.637736  1991.0   \n",
       "1003    306 1885          US          en   17.707331    16.832191  1990.0   \n",
       "\n",
       "      Month_t  Year_diff  \n",
       "2182      2.0       89.0  \n",
       "3274      8.0       75.0  \n",
       "1003      7.0       74.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4803, 16)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.6 Create final dataset\n",
    "df = df_interim.drop(['budget','revenue'], axis=1).copy()\n",
    "display(df.sample(3, random_state=2024))\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Create the model and train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions in train: (3073, 15), validation: (769, 15) and test: (961, 15)\n"
     ]
    }
   ],
   "source": [
    "# Step 3. Create the model based on the dataset\n",
    "# 3.1 Split the dataset into training and testing sets\n",
    "X =  df.drop(columns='vote_average').copy()\n",
    "y = df['vote_average'].copy()/10\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2024)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=2024)\n",
    "print(f'Dimensions in train: {X_train.shape}, validation: {X_val.shape} and test: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>runtime</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>genres_c</th>\n",
       "      <th>keywords_c</th>\n",
       "      <th>producers_c</th>\n",
       "      <th>countries_c</th>\n",
       "      <th>languages_c</th>\n",
       "      <th>budget_log</th>\n",
       "      <th>revenue_log</th>\n",
       "      <th>Year_t</th>\n",
       "      <th>Month_t</th>\n",
       "      <th>Year_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2088</th>\n",
       "      <td>When their computer hacker friend accidentally...</td>\n",
       "      <td>9.662715</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Released</td>\n",
       "      <td>You are now infected.</td>\n",
       "      <td>27 53</td>\n",
       "      <td>236 2157 4959 6614 9714</td>\n",
       "      <td>7405</td>\n",
       "      <td>US</td>\n",
       "      <td>en pl</td>\n",
       "      <td>17.453097</td>\n",
       "      <td>17.213626</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4660</th>\n",
       "      <td>Give Me Shelter is a documentary to raise awar...</td>\n",
       "      <td>0.278981</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>196315</td>\n",
       "      <td></td>\n",
       "      <td>US</td>\n",
       "      <td>en</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2544</th>\n",
       "      <td>On a bet, a gridiron hero at John Hughes High ...</td>\n",
       "      <td>23.423082</td>\n",
       "      <td>89.0</td>\n",
       "      <td>Released</td>\n",
       "      <td>They served you Breakfast. They gave you Pie. ...</td>\n",
       "      <td>35</td>\n",
       "      <td>240 2283 5091 6270 6275 9755 9986 10791 166229...</td>\n",
       "      <td>333 441 2882</td>\n",
       "      <td>US</td>\n",
       "      <td>en</td>\n",
       "      <td>16.588099</td>\n",
       "      <td>18.012236</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1553</th>\n",
       "      <td>Two homicide detectives are on a desperate hun...</td>\n",
       "      <td>79.579532</td>\n",
       "      <td>127.0</td>\n",
       "      <td>Released</td>\n",
       "      <td>Seven deadly sins. Seven ways to die.</td>\n",
       "      <td>80 9648 53</td>\n",
       "      <td>476 703 1470 2231 3597 3857 3927 3932 4138 414...</td>\n",
       "      <td>12 4286 65394</td>\n",
       "      <td>US</td>\n",
       "      <td>en</td>\n",
       "      <td>17.312018</td>\n",
       "      <td>19.606424</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>79.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1279</th>\n",
       "      <td>Alex Rider thinks he is a normal school boy, u...</td>\n",
       "      <td>16.282962</td>\n",
       "      <td>93.0</td>\n",
       "      <td>Released</td>\n",
       "      <td>Rule the school. Save the world.</td>\n",
       "      <td>12 28 10751</td>\n",
       "      <td>392 3272 3650 4391 213102 223438</td>\n",
       "      <td>2268 7289 22514</td>\n",
       "      <td>DE GB US</td>\n",
       "      <td>en</td>\n",
       "      <td>17.504390</td>\n",
       "      <td>16.990972</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3735</th>\n",
       "      <td>Set in 1954, a group of Florida high schoolers...</td>\n",
       "      <td>12.891276</td>\n",
       "      <td>94.0</td>\n",
       "      <td>Released</td>\n",
       "      <td>Keep an eye out for the funniest movie about g...</td>\n",
       "      <td>35</td>\n",
       "      <td>255 293 572 1196 2389 2483 6593 10250 10873 11...</td>\n",
       "      <td>2124 10313</td>\n",
       "      <td>US CA</td>\n",
       "      <td>en</td>\n",
       "      <td>15.201805</td>\n",
       "      <td>18.649633</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>Inspired by the E.C. comics of the 1950s, Geor...</td>\n",
       "      <td>13.661289</td>\n",
       "      <td>120.0</td>\n",
       "      <td>Released</td>\n",
       "      <td>The Most Fun You'll Ever Have... BEING SCARED!</td>\n",
       "      <td>27 35 14</td>\n",
       "      <td>1299 3335 5404 7172 7325 9706 9717 10292 11321...</td>\n",
       "      <td>6194 14179 14180</td>\n",
       "      <td>US</td>\n",
       "      <td>en it</td>\n",
       "      <td>15.894952</td>\n",
       "      <td>16.861401</td>\n",
       "      <td>1982.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>66.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3550</th>\n",
       "      <td>This Canadian made comedy/drama, set in Hamilt...</td>\n",
       "      <td>1.688495</td>\n",
       "      <td>95.0</td>\n",
       "      <td>Released</td>\n",
       "      <td>He's hoping for a miracle. He doesn't have a p...</td>\n",
       "      <td>35 18</td>\n",
       "      <td>6075 10183</td>\n",
       "      <td>803 15689 64570</td>\n",
       "      <td>CA</td>\n",
       "      <td>en</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2951</th>\n",
       "      <td>In Greenwich Village in the early 1960s, gifte...</td>\n",
       "      <td>36.319205</td>\n",
       "      <td>105.0</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18 10402</td>\n",
       "      <td>6382 6706 10228 14512 159944 193419 208992</td>\n",
       "      <td>694 5490 20664</td>\n",
       "      <td>US FR GB</td>\n",
       "      <td>en</td>\n",
       "      <td>16.213406</td>\n",
       "      <td>17.310056</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>A pro tennis player has lost his ambition and ...</td>\n",
       "      <td>16.736734</td>\n",
       "      <td>98.0</td>\n",
       "      <td>Released</td>\n",
       "      <td>She's the golden girl. He's the longshot. It's...</td>\n",
       "      <td>35 10749</td>\n",
       "      <td>1488 1605 2848 5657 9415</td>\n",
       "      <td>33</td>\n",
       "      <td>FR GB</td>\n",
       "      <td>en</td>\n",
       "      <td>17.249498</td>\n",
       "      <td>17.541493</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3073 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               overview  popularity  runtime  \\\n",
       "2088  When their computer hacker friend accidentally...    9.662715     90.0   \n",
       "4660  Give Me Shelter is a documentary to raise awar...    0.278981     90.0   \n",
       "2544  On a bet, a gridiron hero at John Hughes High ...   23.423082     89.0   \n",
       "1553  Two homicide detectives are on a desperate hun...   79.579532    127.0   \n",
       "1279  Alex Rider thinks he is a normal school boy, u...   16.282962     93.0   \n",
       "...                                                 ...         ...      ...   \n",
       "3735  Set in 1954, a group of Florida high schoolers...   12.891276     94.0   \n",
       "417   Inspired by the E.C. comics of the 1950s, Geor...   13.661289    120.0   \n",
       "3550  This Canadian made comedy/drama, set in Hamilt...    1.688495     95.0   \n",
       "2951  In Greenwich Village in the early 1960s, gifte...   36.319205    105.0   \n",
       "1435  A pro tennis player has lost his ambition and ...   16.736734     98.0   \n",
       "\n",
       "        status                                            tagline  \\\n",
       "2088  Released                              You are now infected.   \n",
       "4660  Released                                                NaN   \n",
       "2544  Released  They served you Breakfast. They gave you Pie. ...   \n",
       "1553  Released              Seven deadly sins. Seven ways to die.   \n",
       "1279  Released                   Rule the school. Save the world.   \n",
       "...        ...                                                ...   \n",
       "3735  Released  Keep an eye out for the funniest movie about g...   \n",
       "417   Released     The Most Fun You'll Ever Have... BEING SCARED!   \n",
       "3550  Released  He's hoping for a miracle. He doesn't have a p...   \n",
       "2951  Released                                                NaN   \n",
       "1435  Released  She's the golden girl. He's the longshot. It's...   \n",
       "\n",
       "         genres_c                                         keywords_c  \\\n",
       "2088        27 53                            236 2157 4959 6614 9714   \n",
       "4660           99                                             196315   \n",
       "2544           35  240 2283 5091 6270 6275 9755 9986 10791 166229...   \n",
       "1553   80 9648 53  476 703 1470 2231 3597 3857 3927 3932 4138 414...   \n",
       "1279  12 28 10751                   392 3272 3650 4391 213102 223438   \n",
       "...           ...                                                ...   \n",
       "3735           35  255 293 572 1196 2389 2483 6593 10250 10873 11...   \n",
       "417      27 35 14  1299 3335 5404 7172 7325 9706 9717 10292 11321...   \n",
       "3550        35 18                                         6075 10183   \n",
       "2951     18 10402         6382 6706 10228 14512 159944 193419 208992   \n",
       "1435     35 10749                           1488 1605 2848 5657 9415   \n",
       "\n",
       "           producers_c countries_c languages_c  budget_log  revenue_log  \\\n",
       "2088              7405          US       en pl   17.453097    17.213626   \n",
       "4660                            US          en    0.000000     0.000000   \n",
       "2544      333 441 2882          US          en   16.588099    18.012236   \n",
       "1553     12 4286 65394          US          en   17.312018    19.606424   \n",
       "1279   2268 7289 22514    DE GB US          en   17.504390    16.990972   \n",
       "...                ...         ...         ...         ...          ...   \n",
       "3735        2124 10313       US CA          en   15.201805    18.649633   \n",
       "417   6194 14179 14180          US       en it   15.894952    16.861401   \n",
       "3550   803 15689 64570          CA          en    0.000000     0.000000   \n",
       "2951    694 5490 20664    US FR GB          en   16.213406    17.310056   \n",
       "1435                33       FR GB          en   17.249498    17.541493   \n",
       "\n",
       "      Year_t  Month_t  Year_diff  \n",
       "2088  2006.0      8.0       90.0  \n",
       "4660  2014.0      6.0       98.0  \n",
       "2544  2001.0     12.0       85.0  \n",
       "1553  1995.0      9.0       79.0  \n",
       "1279  2006.0      7.0       90.0  \n",
       "...      ...      ...        ...  \n",
       "3735  1981.0     11.0       65.0  \n",
       "417   1982.0     11.0       66.0  \n",
       "3550  2004.0      9.0       88.0  \n",
       "2951  2013.0     10.0       97.0  \n",
       "1435  2004.0      9.0       88.0  \n",
       "\n",
       "[3073 rows x 15 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll use tensorflow datasets, with the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['When their computer hacker friend accidentally channels a mysterious wireless signal, a group of co-eds rally to stop a terrifying evil from taking over the world.']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['overview'].filter(items=[2088]).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type float).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/data/util/structure.py:105\u001b[0m, in \u001b[0;36mnormalize_element\u001b[0;34m(element, element_signature)\u001b[0m\n\u001b[1;32m    104\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 105\u001b[0m     spec \u001b[38;5;241m=\u001b[39m \u001b[43mtype_spec_from_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_fallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    107\u001b[0m   \u001b[38;5;66;03m# TypeError indicates it was not possible to compute a `TypeSpec` for\u001b[39;00m\n\u001b[1;32m    108\u001b[0m   \u001b[38;5;66;03m# the value. As a fallback try converting the value to a tensor.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/data/util/structure.py:514\u001b[0m, in \u001b[0;36mtype_spec_from_value\u001b[0;34m(element, use_fallback)\u001b[0m\n\u001b[1;32m    511\u001b[0m     logging\u001b[38;5;241m.\u001b[39mvlog(\n\u001b[1;32m    512\u001b[0m         \u001b[38;5;241m3\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to convert \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m to tensor: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mtype\u001b[39m(element)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, e))\n\u001b[0;32m--> 514\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not build a `TypeSpec` for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m with type \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    515\u001b[0m     element,\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28mtype\u001b[39m(element)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m))\n",
      "\u001b[0;31mTypeError\u001b[0m: Could not build a `TypeSpec` for 2088    When their computer hacker friend accidentally...\n4660    Give Me Shelter is a documentary to raise awar...\n2544    On a bet, a gridiron hero at John Hughes High ...\n1553    Two homicide detectives are on a desperate hun...\n1279    Alex Rider thinks he is a normal school boy, u...\n                              ...                        \n3735    Set in 1954, a group of Florida high schoolers...\n417     Inspired by the E.C. comics of the 1950s, Geor...\n3550    This Canadian made comedy/drama, set in Hamilt...\n2951    In Greenwich Village in the early 1960s, gifte...\n1435    A pro tennis player has lost his ambition and ...\nName: overview, Length: 3073, dtype: object with type Series",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 14\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmake_data\u001b[39m(X,y):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mfrom_tensor_slices(\n\u001b[1;32m      3\u001b[0m         {\n\u001b[1;32m      4\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenres_c\u001b[39m\u001b[38;5;124m'\u001b[39m: X[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenres_c\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m         }\n\u001b[1;32m     13\u001b[0m     )\n\u001b[0;32m---> 14\u001b[0m train \u001b[38;5;241m=\u001b[39m \u001b[43mmake_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m val \u001b[38;5;241m=\u001b[39m make_data(X_val, y_val)\n\u001b[1;32m     16\u001b[0m test \u001b[38;5;241m=\u001b[39m make_data(X_test, y_test)\n",
      "Cell \u001b[0;32mIn[46], line 2\u001b[0m, in \u001b[0;36mmake_data\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmake_data\u001b[39m(X,y):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_tensor_slices\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgenres_c\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgenres_c\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mkeywords_c\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mkeywords_c\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moverview\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moverview\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m#'producers_c': X['producers_c'],\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m#'countries_c': X['countries_c'],\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m#'languages_c': X['languages_c'],\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m#'tagline': X['tagline'],\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m#'scalars': X[['budget_log','revenue_log','popularity','runtime','Year_diff','Month_t']]\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py:825\u001b[0m, in \u001b[0;36mDatasetV2.from_tensor_slices\u001b[0;34m(tensors, name)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;66;03m# Loaded lazily due to a circular dependency (dataset_ops ->\u001b[39;00m\n\u001b[1;32m    822\u001b[0m \u001b[38;5;66;03m# from_tensor_slices_op -> dataset_ops).\u001b[39;00m\n\u001b[1;32m    823\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m from_tensor_slices_op\n\u001b[0;32m--> 825\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfrom_tensor_slices_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_tensor_slices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/data/ops/from_tensor_slices_op.py:25\u001b[0m, in \u001b[0;36m_from_tensor_slices\u001b[0;34m(tensors, name)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_from_tensor_slices\u001b[39m(tensors, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 25\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_TensorSliceDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/data/ops/from_tensor_slices_op.py:33\u001b[0m, in \u001b[0;36m_TensorSliceDataset.__init__\u001b[0;34m(self, element, is_files, name)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, element, is_files\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     32\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"See `Dataset.from_tensor_slices` for details.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m   element \u001b[38;5;241m=\u001b[39m \u001b[43mstructure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43melement\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m   batched_spec \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mtype_spec_from_value(element)\n\u001b[1;32m     35\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensors \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mto_batched_tensor_list(batched_spec, element)\n",
      "File \u001b[0;32m~/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/data/util/structure.py:110\u001b[0m, in \u001b[0;36mnormalize_element\u001b[0;34m(element, element_signature)\u001b[0m\n\u001b[1;32m    105\u001b[0m     spec \u001b[38;5;241m=\u001b[39m type_spec_from_value(t, use_fallback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    107\u001b[0m   \u001b[38;5;66;03m# TypeError indicates it was not possible to compute a `TypeSpec` for\u001b[39;00m\n\u001b[1;32m    108\u001b[0m   \u001b[38;5;66;03m# the value. As a fallback try converting the value to a tensor.\u001b[39;00m\n\u001b[1;32m    109\u001b[0m   normalized_components\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 110\u001b[0m       \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcomponent_\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    112\u001b[0m   \u001b[38;5;66;03m# To avoid a circular dependency between dataset_ops and structure,\u001b[39;00m\n\u001b[1;32m    113\u001b[0m   \u001b[38;5;66;03m# we check the class name instead of using `isinstance`.\u001b[39;00m\n\u001b[1;32m    114\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetSpec\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/profiler/trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m Trace(trace_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrace_kwargs):\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:696\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m    694\u001b[0m \u001b[38;5;66;03m# TODO(b/142518781): Fix all call-sites and remove redundant arg\u001b[39;00m\n\u001b[1;32m    695\u001b[0m preferred_dtype \u001b[38;5;241m=\u001b[39m preferred_dtype \u001b[38;5;129;01mor\u001b[39;00m dtype_hint\n\u001b[0;32m--> 696\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor_conversion_registry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreferred_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccepted_result_types\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/framework/tensor_conversion_registry.py:234\u001b[0m, in \u001b[0;36mconvert\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001b[0m\n\u001b[1;32m    225\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    226\u001b[0m           _add_error_prefix(\n\u001b[1;32m    227\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconversion_func\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m for type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactual = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mret\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mbase_dtype\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    231\u001b[0m               name\u001b[38;5;241m=\u001b[39mname))\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 234\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mconversion_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m    237\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:335\u001b[0m, in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_tensor_conversion_function\u001b[39m(v, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    333\u001b[0m                                          as_ref\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    334\u001b[0m   _ \u001b[38;5;241m=\u001b[39m as_ref\n\u001b[0;32m--> 335\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/ops/weak_tensor_ops.py:142\u001b[0m, in \u001b[0;36mweak_tensor_binary_op_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    141\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mis_auto_dtype_conversion_enabled():\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m   bound_arguments \u001b[38;5;241m=\u001b[39m signature\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    144\u001b[0m   bound_arguments\u001b[38;5;241m.\u001b[39mapply_defaults()\n",
      "File \u001b[0;32m~/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:271\u001b[0m, in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconstant\u001b[39m(\n\u001b[1;32m    174\u001b[0m     value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConst\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    175\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[ops\u001b[38;5;241m.\u001b[39mOperation, ops\u001b[38;5;241m.\u001b[39m_EagerTensorBase]:\n\u001b[1;32m    176\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \n\u001b[1;32m    178\u001b[0m \u001b[38;5;124;03m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;124;03m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 271\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mallow_broadcast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:284\u001b[0m, in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.constant\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    283\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m--> 284\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_eager_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    286\u001b[0m const_tensor \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39m_create_graph_constant(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     value, dtype, shape, name, verify_shape, allow_broadcast\n\u001b[1;32m    288\u001b[0m )\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m const_tensor\n",
      "File \u001b[0;32m~/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:296\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_eager_impl\u001b[39m(\n\u001b[1;32m    293\u001b[0m     ctx, value, dtype, shape, verify_shape\n\u001b[1;32m    294\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ops\u001b[38;5;241m.\u001b[39m_EagerTensorBase:\n\u001b[1;32m    295\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 296\u001b[0m   t \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_eager_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    297\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n",
      "File \u001b[0;32m~/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:103\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    101\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    102\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type float)."
     ]
    }
   ],
   "source": [
    "def make_data(X,y):\n",
    "    return tf.data.Dataset.from_tensor_slices(\n",
    "        {\n",
    "            'genres_c': X['genres_c'],\n",
    "            'keywords_c': X['keywords_c'],\n",
    "            'overview': X['overview'],\n",
    "            #'producers_c': X['producers_c'],\n",
    "            #'countries_c': X['countries_c'],\n",
    "            #'languages_c': X['languages_c'],\n",
    "            #'tagline': X['tagline'],\n",
    "            #'scalars': X[['budget_log','revenue_log','popularity','runtime','Year_diff','Month_t']]\n",
    "        }\n",
    "    )\n",
    "train = make_data(X_train, y_train)\n",
    "val = make_data(X_val, y_val)\n",
    "test = make_data(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2088    0.50\n",
       "4660    0.00\n",
       "2544    0.55\n",
       "1553    0.81\n",
       "1279    0.51\n",
       "        ... \n",
       "3735    0.61\n",
       "417     0.67\n",
       "3550    0.73\n",
       "2951    0.72\n",
       "1435    0.60\n",
       "Name: vote_average, Length: 3073, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train['s']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type float).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/data/util/structure.py:105\u001b[0m, in \u001b[0;36mnormalize_element\u001b[0;34m(element, element_signature)\u001b[0m\n\u001b[1;32m    104\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 105\u001b[0m     spec \u001b[38;5;241m=\u001b[39m \u001b[43mtype_spec_from_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_fallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    107\u001b[0m   \u001b[38;5;66;03m# TypeError indicates it was not possible to compute a `TypeSpec` for\u001b[39;00m\n\u001b[1;32m    108\u001b[0m   \u001b[38;5;66;03m# the value. As a fallback try converting the value to a tensor.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/data/util/structure.py:514\u001b[0m, in \u001b[0;36mtype_spec_from_value\u001b[0;34m(element, use_fallback)\u001b[0m\n\u001b[1;32m    511\u001b[0m     logging\u001b[38;5;241m.\u001b[39mvlog(\n\u001b[1;32m    512\u001b[0m         \u001b[38;5;241m3\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to convert \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m to tensor: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mtype\u001b[39m(element)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, e))\n\u001b[0;32m--> 514\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not build a `TypeSpec` for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m with type \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    515\u001b[0m     element,\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28mtype\u001b[39m(element)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m))\n",
      "\u001b[0;31mTypeError\u001b[0m: Could not build a `TypeSpec` for 2088    When their computer hacker friend accidentally...\n4660    Give Me Shelter is a documentary to raise awar...\n2544    On a bet, a gridiron hero at John Hughes High ...\n1553    Two homicide detectives are on a desperate hun...\n1279    Alex Rider thinks he is a normal school boy, u...\n                              ...                        \n3735    Set in 1954, a group of Florida high schoolers...\n417     Inspired by the E.C. comics of the 1950s, Geor...\n3550    This Canadian made comedy/drama, set in Hamilt...\n2951    In Greenwich Village in the early 1960s, gifte...\n1435    A pro tennis player has lost his ambition and ...\nName: overview, Length: 3073, dtype: object with type Series",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmake_data\u001b[39m(X):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mfrom_tensor_slices(\n\u001b[1;32m      3\u001b[0m         {\n\u001b[1;32m      4\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverview\u001b[39m\u001b[38;5;124m\"\u001b[39m: X[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverview\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      5\u001b[0m         }\n\u001b[1;32m      6\u001b[0m     )\n\u001b[0;32m----> 7\u001b[0m train \u001b[38;5;241m=\u001b[39m \u001b[43mmake_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[53], line 2\u001b[0m, in \u001b[0;36mmake_data\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmake_data\u001b[39m(X):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_tensor_slices\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moverview\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moverview\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py:825\u001b[0m, in \u001b[0;36mDatasetV2.from_tensor_slices\u001b[0;34m(tensors, name)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;66;03m# Loaded lazily due to a circular dependency (dataset_ops ->\u001b[39;00m\n\u001b[1;32m    822\u001b[0m \u001b[38;5;66;03m# from_tensor_slices_op -> dataset_ops).\u001b[39;00m\n\u001b[1;32m    823\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m from_tensor_slices_op\n\u001b[0;32m--> 825\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfrom_tensor_slices_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_tensor_slices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/data/ops/from_tensor_slices_op.py:25\u001b[0m, in \u001b[0;36m_from_tensor_slices\u001b[0;34m(tensors, name)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_from_tensor_slices\u001b[39m(tensors, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 25\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_TensorSliceDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/data/ops/from_tensor_slices_op.py:33\u001b[0m, in \u001b[0;36m_TensorSliceDataset.__init__\u001b[0;34m(self, element, is_files, name)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, element, is_files\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     32\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"See `Dataset.from_tensor_slices` for details.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m   element \u001b[38;5;241m=\u001b[39m \u001b[43mstructure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43melement\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m   batched_spec \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mtype_spec_from_value(element)\n\u001b[1;32m     35\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensors \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mto_batched_tensor_list(batched_spec, element)\n",
      "File \u001b[0;32m~/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/data/util/structure.py:110\u001b[0m, in \u001b[0;36mnormalize_element\u001b[0;34m(element, element_signature)\u001b[0m\n\u001b[1;32m    105\u001b[0m     spec \u001b[38;5;241m=\u001b[39m type_spec_from_value(t, use_fallback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    107\u001b[0m   \u001b[38;5;66;03m# TypeError indicates it was not possible to compute a `TypeSpec` for\u001b[39;00m\n\u001b[1;32m    108\u001b[0m   \u001b[38;5;66;03m# the value. As a fallback try converting the value to a tensor.\u001b[39;00m\n\u001b[1;32m    109\u001b[0m   normalized_components\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 110\u001b[0m       \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcomponent_\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    112\u001b[0m   \u001b[38;5;66;03m# To avoid a circular dependency between dataset_ops and structure,\u001b[39;00m\n\u001b[1;32m    113\u001b[0m   \u001b[38;5;66;03m# we check the class name instead of using `isinstance`.\u001b[39;00m\n\u001b[1;32m    114\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetSpec\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/profiler/trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m Trace(trace_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrace_kwargs):\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:696\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m    694\u001b[0m \u001b[38;5;66;03m# TODO(b/142518781): Fix all call-sites and remove redundant arg\u001b[39;00m\n\u001b[1;32m    695\u001b[0m preferred_dtype \u001b[38;5;241m=\u001b[39m preferred_dtype \u001b[38;5;129;01mor\u001b[39;00m dtype_hint\n\u001b[0;32m--> 696\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor_conversion_registry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreferred_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccepted_result_types\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/framework/tensor_conversion_registry.py:234\u001b[0m, in \u001b[0;36mconvert\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001b[0m\n\u001b[1;32m    225\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    226\u001b[0m           _add_error_prefix(\n\u001b[1;32m    227\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconversion_func\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m for type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactual = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mret\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mbase_dtype\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    231\u001b[0m               name\u001b[38;5;241m=\u001b[39mname))\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 234\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mconversion_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m    237\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:335\u001b[0m, in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_tensor_conversion_function\u001b[39m(v, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    333\u001b[0m                                          as_ref\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    334\u001b[0m   _ \u001b[38;5;241m=\u001b[39m as_ref\n\u001b[0;32m--> 335\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/ops/weak_tensor_ops.py:142\u001b[0m, in \u001b[0;36mweak_tensor_binary_op_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    141\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mis_auto_dtype_conversion_enabled():\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m   bound_arguments \u001b[38;5;241m=\u001b[39m signature\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    144\u001b[0m   bound_arguments\u001b[38;5;241m.\u001b[39mapply_defaults()\n",
      "File \u001b[0;32m~/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:271\u001b[0m, in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconstant\u001b[39m(\n\u001b[1;32m    174\u001b[0m     value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConst\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    175\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[ops\u001b[38;5;241m.\u001b[39mOperation, ops\u001b[38;5;241m.\u001b[39m_EagerTensorBase]:\n\u001b[1;32m    176\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \n\u001b[1;32m    178\u001b[0m \u001b[38;5;124;03m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;124;03m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 271\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mallow_broadcast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:284\u001b[0m, in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.constant\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    283\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m--> 284\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_eager_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    286\u001b[0m const_tensor \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39m_create_graph_constant(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     value, dtype, shape, name, verify_shape, allow_broadcast\n\u001b[1;32m    288\u001b[0m )\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m const_tensor\n",
      "File \u001b[0;32m~/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:296\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_eager_impl\u001b[39m(\n\u001b[1;32m    293\u001b[0m     ctx, value, dtype, shape, verify_shape\n\u001b[1;32m    294\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ops\u001b[38;5;241m.\u001b[39m_EagerTensorBase:\n\u001b[1;32m    295\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 296\u001b[0m   t \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_eager_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    297\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n",
      "File \u001b[0;32m~/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:103\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    101\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    102\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type float)."
     ]
    }
   ],
   "source": [
    "def make_data(X):\n",
    "    return tf.data.Dataset.from_tensor_slices(\n",
    "        {\n",
    "            \"overview\": X[\"overview\"]\n",
    "        }\n",
    "    )\n",
    "train = make_data(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2088    0.50\n",
       "4660    0.00\n",
       "2544    0.55\n",
       "1553    0.81\n",
       "1279    0.51\n",
       "        ... \n",
       "3735    0.61\n",
       "417     0.67\n",
       "3550    0.73\n",
       "2951    0.72\n",
       "1435    0.60\n",
       "Name: vote_average, Length: 3073, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TensorSliceDataset element_spec={'genres_c': TensorSpec(shape=(), dtype=tf.string, name=None)}>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.data.Dataset.from_tensor_slices({'genres_c':X_train['genres_c']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "[1] https://github.com/PhilChodrow/PIC16B/blob/7d12d32e070e7ff3840b971c0ce4185ef1911796/discussion/tmdb.ipynb#L758"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
