{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **IMDB Sentiment Analysis** - Binary Classification\n",
    "- **Date**: Mar 8, 2024  \n",
    "- **Task**: Create a model to classify reviews into positive or negative using the attention mechanism \n",
    "- **Procedure**: Analyze data with pandas, create nn model in TensorFlow, implement transformers\n",
    "- **Dataset source**: https://www.kaggle.com/datasets/columbine/imdb-dataset-sentiment-analysis-in-csv-format/data   \n",
    "- **References**: https://github.com/PhilChodrow/PIC16B/blob/7d12d32e070e7ff3840b971c0ce4185ef1911796/discussion/tmdb.ipynb#L758"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 0. Load libraries and custom functions\n",
    "# Matrices and datasets ------------------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Graphics -------------------------------------------------------------\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Text processors\n",
    "import re\n",
    "import string\n",
    "#import nltk\n",
    "#from nltk.corpus import stopwords\n",
    "#nltk.download('stopwords')\n",
    "from wordcloud import WordCloud\n",
    "# Machine Learning -----------------------------------------------------\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# Deep Learning --------------------------------------------------------\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from keras.layers import TextVectorization\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Custom functions -----------------------------------------------------\n",
    "def sentence_fixed_split(x:list, words: int):\n",
    "    \"\"\"\n",
    "    Split a list of sentences into a list of fixed length sentences.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x: list\n",
    "        sentence as a list of words\n",
    "    words: int \n",
    "        number of fixed words required\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        a list of fixed length sentences\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "        df = pd.DataFrame({'text':['In our darkest hour, I will prevail as always']})\n",
    "        df['text'] = df['text'].apply(lambda x: sentence_fixed_split(x, 4))\n",
    "        df = df.explode('text')\n",
    "        text\n",
    "        ----\n",
    "        In our darkest hour,\n",
    "        I will prevail as\n",
    "        always\n",
    "    \"\"\"\n",
    "    words_lenght = len(x.split(' '))\n",
    "    if words_lenght>1 and words > 1 and words_lenght > words:\n",
    "        return [' '.join(x.split(' ')[i:i+words]) for i in range(0, len(x.split(' ')), words)]\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "def plot_accuracy_loss_tfmodel(model, epochs: int):\n",
    "    '''\n",
    "    Plots the accuracy and loss curves of a TensorFlow model\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model\n",
    "        A tensorflow model\n",
    "    epochs\n",
    "        Number of epochs the model was trained for\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A 2 columns 1 row plot of accuracy and loss curves\n",
    "    '''\n",
    "    epochs_range = range(1, epochs + 1)\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(epochs_range, model.history['accuracy'], 'b', label='Training accuracy')\n",
    "    plt.plot(epochs_range, model.history['val_accuracy'], 'b--', label='Validation accuracy')\n",
    "    plt.legend()\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(epochs_range, model.history['loss'], 'b', label='Training loss')\n",
    "    plt.plot(epochs_range, model.history['val_loss'], 'b--', label='Validation loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred):\n",
    "    '''\n",
    "    Plots the confusion matrix and precision/recall metrics\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true\n",
    "        True labels\n",
    "    y_pred\n",
    "        Predicted labels\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A plot and the metrics\n",
    "    '''\n",
    "    cm = confusion_matrix(y_pred, y_true)\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt='g')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "    plt.close\n",
    "    print(classification_report(y_pred, y_true))\n",
    "\n",
    "def analyze_wrong_predictions(dataset, y_pred, samples):\n",
    "    '''\n",
    "    Prints samples of wrong predictions on a dataset\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset\n",
    "        data with values\n",
    "    y_pred\n",
    "        list of predictions\n",
    "    samples\n",
    "        number of samples required\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Text with true label and reviews\n",
    "    '''\n",
    "    dataset['prediction'] = y_pred\n",
    "    for index, row in dataset[dataset.label != dataset.prediction].sample(samples).iterrows():\n",
    "        print(f'label: {row.label}, {row.text}')\n",
    "        print('--------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40000 entries, 0 to 39999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    40000 non-null  object\n",
      " 1   label   40000 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 625.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# Step 1. Load data\n",
    "# 1.1 Read csv and get basic info\n",
    "df_train = pd.read_csv('../data/01_IMDB_Train.csv')\n",
    "df_val = pd.read_csv('../data/01_IMDB_Valid.csv')\n",
    "df_test = pd.read_csv('../data/01_IMDB_Test.csv')\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.4 Preprocess data based on observed information\n",
    "df_train = df_train[~df_train.text.duplicated()]\n",
    "df_val = df_val[~df_val.text.duplicated()]\n",
    "df_train.reset_index(drop=True, inplace=True)\n",
    "df_val.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
