{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/alexismena/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Step 0. Load libraries and custom functions\n",
    "# Matrices and datasets ------------------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Graphics -------------------------------------------------------------\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Text processors\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from wordcloud import WordCloud\n",
    "# Machine Learning -----------------------------------------------------\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# Deep Learning --------------------------------------------------------\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from keras.layers import TextVectorization\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Custom functions -----------------------------------------------------\n",
    "def sentence_fixed_split(x:list, words: int):\n",
    "    \"\"\"\n",
    "    Split a list of sentences into a list of fixed length sentences.\n",
    "    param x: sentence as a list of words\n",
    "    param words: number of fixed words required\n",
    "    return: list of fixed length sentences\n",
    "    \"\"\"\n",
    "    words_lenght = len(x.split(' '))\n",
    "    if words_lenght>1 and words > 1 and words_lenght > words:\n",
    "        return [' '.join(x.split(' ')[i:i+words]) for i in range(0, len(x.split(' ')), words)]\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     50000 non-null  object\n",
      " 1   sentiment  50000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 781.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# Step 1. Load data\n",
    "# 1.1 Read csv and get basic info\n",
    "df_raw = pd.read_csv('../data/01_IMDB_Dataset_HuggingFace.csv')\n",
    "df_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16441</th>\n",
       "      <td>Like most musicals of the era, one must check ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26819</th>\n",
       "      <td>I saw this show about 3-4 years ago. It was da...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9242</th>\n",
       "      <td>One of, if not THE most visually beautiful fil...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16234</th>\n",
       "      <td>Although this lovely work of art does use some...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19184</th>\n",
       "      <td>Don't waste your time or money on this one. Th...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34763</th>\n",
       "      <td>Twelve Monkeys is an insane time-travelling, a...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36781</th>\n",
       "      <td>Just when you thought it was safe to go back i...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9082</th>\n",
       "      <td>at first i thought it was bad because i had gr...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39944</th>\n",
       "      <td>I wouldn't exactly call this a good movie, in ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38247</th>\n",
       "      <td>This movie is very bad. In fact, the only reas...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "16441  Like most musicals of the era, one must check ...  negative\n",
       "26819  I saw this show about 3-4 years ago. It was da...  positive\n",
       "9242   One of, if not THE most visually beautiful fil...  positive\n",
       "16234  Although this lovely work of art does use some...  positive\n",
       "19184  Don't waste your time or money on this one. Th...  negative\n",
       "34763  Twelve Monkeys is an insane time-travelling, a...  positive\n",
       "36781  Just when you thought it was safe to go back i...  negative\n",
       "9082   at first i thought it was bad because i had gr...  negative\n",
       "39944  I wouldn't exactly call this a good movie, in ...  negative\n",
       "38247  This movie is very bad. In fact, the only reas...  negative"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.2 Get a sample\n",
    "df_raw.sample(10, random_state=2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "418"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.3 Verify if there are duplicates\n",
    "df_raw['review'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 49582 entries, 0 to 49999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     49582 non-null  object\n",
      " 1   sentiment  49582 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# 1.4 Preprocess data based on observed information\n",
    "df_interim = df_raw.copy()\n",
    "df_interim = df_interim[~df_interim.review.duplicated()]\n",
    "df_interim.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.5 Create the final dataframe\n",
    "df_final = df_interim.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.6 Create your train, validation and test datasets\n",
    "test_split = 0.3\n",
    "val_split = 0.5\n",
    "train_df, test_df = train_test_split(\n",
    "    df_final,\n",
    "    test_size=test_split,\n",
    "    stratify=df_final['sentiment'].values,\n",
    "    random_state=2024\n",
    ")\n",
    "\n",
    "val_df = test_df.sample(frac=val_split)\n",
    "test_df = test_df.drop(val_df.index)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df = val_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2. Create a basic analysis\n",
    "# 2.1 Get basic info\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 Get a summary of the data\n",
    "train_df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3 Get words statistics\n",
    "train_df['review'].apply(lambda x: len(x.split())).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.4 Show histogram of word count\n",
    "train_df['review'].apply(lambda x: len(x.split(' '))).hist(bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.5 Show histogram of word count stratified by sentiment\n",
    "(train_df\n",
    " .assign(word_count = train_df['review'].apply(lambda x: len(x.split())))\n",
    " .hist('word_count', by='sentiment', grid=True, sharey=True, bins=30)\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.6 Show boxplot of word count stratified by sentiment\n",
    "(train_df\n",
    " .assign(word_count = train_df['review'].apply(lambda x: len(x.split())))\n",
    " .boxplot('word_count', by='sentiment')\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.7 List total words in our vocabulary\n",
    "train_df['review'].str.split(expand=True).stack().value_counts().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.8 List most frequent words in reviews\n",
    "train_df['review'].str.split(expand=True).stack().value_counts()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.9 View the wordcloud of reviews without stopwords\n",
    "text = ' '.join(i.lower() for i in train_df['review'])\n",
    "wordcloud = WordCloud(max_words=100, \n",
    "                      stopwords=None, \n",
    "                      background_color='White', \n",
    "                      collocations=False).generate(text)\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After analyzing the dataset, we need to create a processing pipeline that:\n",
    "- removes stopwords\n",
    "- removes html tags\n",
    "- removes punctuations\n",
    "- uses a compact vocabulary\n",
    "- lowercases the words\n",
    "- corrects mispelled words like soooo, muuuuch, etc (more than 3 vowels)\n",
    "- encode sentiment into 1 or 0 \n",
    "\n",
    "For our traning task, we can split longest reviews into segments or just \n",
    "truncate the review up to 500 words and eliminate the rest, but it \n",
    "results in losing some information, so we will try both aproaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3. Train and execute model iter 1.\n",
    "# Create a copy\n",
    "train_ds    = train_df.copy()\n",
    "val_ds      = val_df.copy()\n",
    "test_ds     = test_df.copy()\n",
    "# Encode sentiment response variable\n",
    "train_ds['sentiment']   = train_ds['sentiment'].apply(lambda x: 1 if x == 'positive' else 0)\n",
    "val_ds['sentiment']     = val_ds['sentiment'].apply(lambda x: 1 if x == 'positive' else 0)\n",
    "test_ds['sentiment']    = test_ds['sentiment'].apply(lambda x: 1 if x == 'positive' else 0)\n",
    "# Tokenize words on the dataset\n",
    "tokenizer = Tokenizer(num_words=20000, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(train_ds['review'])\n",
    "word_index = tokenizer.word_index\n",
    "sequences = tokenizer.texts_to_sequences(train_ds['review'])\n",
    "padded_sequences_train = pad_sequences(sequences, maxlen=200, truncating='post')\n",
    "sequences = tokenizer.texts_to_sequences(val_ds['review'])\n",
    "padded_sequences_val = pad_sequences(sequences, maxlen=200, truncating='post')\n",
    "sequences = tokenizer.texts_to_sequences(test_ds['review'])\n",
    "padded_sequences_test = pad_sequences(sequences, maxlen=200, truncating='post')\n",
    "# Create model\n",
    "inputs = keras.Input(shape=(200,))\n",
    "x = layers.Dense(26, activation='relu')(inputs)\n",
    "x = layers.Dropout(0.4)(x)\n",
    "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.compile(optimizer='rmsprop',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "model.summary()\n",
    "model.fit(padded_sequences_train, train_ds['sentiment'], epochs=10, batch_size=32, validation_data=(padded_sequences_val, val_ds['sentiment']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-23 13:03:34.664130: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1116/1116 [==============================] - 12s 10ms/step - loss: 9.6570 - accuracy: 0.9959 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "1116/1116 [==============================] - 11s 10ms/step - loss: 0.2249 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "1116/1116 [==============================] - 11s 10ms/step - loss: 0.0565 - accuracy: 0.9999 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "1116/1116 [==============================] - 11s 10ms/step - loss: 0.0810 - accuracy: 0.9999 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "1116/1116 [==============================] - 11s 10ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "1116/1116 [==============================] - 11s 10ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "1116/1116 [==============================] - 11s 10ms/step - loss: 0.0959 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "1116/1116 [==============================] - 11s 10ms/step - loss: 0.0845 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "1116/1116 [==============================] - 11s 10ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "1116/1116 [==============================] - 11s 10ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2d90b5e10>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and execute model iter 2\n",
    "# Recode data and format text\n",
    "df_final['sentiment'] = df_final['sentiment'].apply(lambda x: 1 if x=='positive' else 0)\n",
    "df_final['review'] = df_final['review'].apply(lambda x: x.lower())\n",
    "df_final['review'] = df_final['review'].str.replace(r'(<.*?>)','',regex=True)\n",
    "df_final['review'] = df_final['review'].str.strip()\n",
    "# Preprocess the data\n",
    "tokenizer = Tokenizer(num_words=20000,oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(df_final['review'])\n",
    "vocab = tokenizer.word_index\n",
    "sequences = tokenizer.texts_to_sequences(df_final['review'])\n",
    "X = pad_sequences(sequences, maxlen=200, truncating='post')\n",
    "\n",
    "#Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    df_final['sentiment'], \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=2024)\n",
    "# Build the model\n",
    "inputs = keras.Input(shape=(200,))\n",
    "x = layers.Dense(64, activation='relu')(inputs)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs, name='sentiment_model')\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, validation_split=0.1, epochs=10, batch_size=32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "310/310 [==============================] - 1s 2ms/step\n",
      "Test accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test).round()\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Test accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This night it was fantastic so you now or was it question_mark ']\n"
     ]
    }
   ],
   "source": [
    "mudf = pd.DataFrame({'id':[1], 'textio':['This night, it was... fantastic!, so you now; or was it?']})\n",
    "mudf['textio'] = mudf['textio'].str.replace(r'''['!,.;]''', '', regex=True)\n",
    "mudf['textio'] = mudf['textio'].str.replace(r'[?]', ' question_mark ', regex=True)\n",
    "print(mudf['textio'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40000 entries, 0 to 39999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    40000 non-null  object\n",
      " 1   label   40000 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 625.1+ KB\n",
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-23 17:00:56.193188: W tensorflow/core/framework/op_kernel.cc:1827] INVALID_ARGUMENT: TypeError: 'SparseTensor' object is not subscriptable\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n",
      "    return func(device, token, args)\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 146, in __call__\n",
      "    outputs = self._call(device, args)\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 153, in _call\n",
      "    ret = self._func(*args)\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/data_adapter.py\", line 519, in py_method\n",
      "    return [slice_array(inp) for inp in flat_inputs]\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/data_adapter.py\", line 519, in <listcomp>\n",
      "    return [slice_array(inp) for inp in flat_inputs]\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/data_adapter.py\", line 515, in slice_array\n",
      "    return training_utils.slice_arrays(\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/training_utils.py\", line 47, in slice_arrays\n",
      "    entries = [[x[i : i + 1] for i in indices] for x in arrays]\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/training_utils.py\", line 47, in <listcomp>\n",
      "    entries = [[x[i : i + 1] for i in indices] for x in arrays]\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/training_utils.py\", line 47, in <listcomp>\n",
      "    entries = [[x[i : i + 1] for i in indices] for x in arrays]\n",
      "\n",
      "TypeError: 'SparseTensor' object is not subscriptable\n",
      "\n",
      "\n",
      "2024-02-23 17:00:56.193213: W tensorflow/core/framework/op_kernel.cc:1827] INVALID_ARGUMENT: TypeError: 'SparseTensor' object is not subscriptable\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n",
      "    return func(device, token, args)\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 146, in __call__\n",
      "    outputs = self._call(device, args)\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 153, in _call\n",
      "    ret = self._func(*args)\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/data_adapter.py\", line 519, in py_method\n",
      "    return [slice_array(inp) for inp in flat_inputs]\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/data_adapter.py\", line 519, in <listcomp>\n",
      "    return [slice_array(inp) for inp in flat_inputs]\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/data_adapter.py\", line 515, in slice_array\n",
      "    return training_utils.slice_arrays(\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/training_utils.py\", line 47, in slice_arrays\n",
      "    entries = [[x[i : i + 1] for i in indices] for x in arrays]\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/training_utils.py\", line 47, in <listcomp>\n",
      "    entries = [[x[i : i + 1] for i in indices] for x in arrays]\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/training_utils.py\", line 47, in <listcomp>\n",
      "    entries = [[x[i : i + 1] for i in indices] for x in arrays]\n",
      "\n",
      "TypeError: 'SparseTensor' object is not subscriptable\n",
      "\n",
      "\n",
      "2024-02-23 17:00:56.193281: W tensorflow/core/framework/op_kernel.cc:1827] INVALID_ARGUMENT: TypeError: 'SparseTensor' object is not subscriptable\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n",
      "    return func(device, token, args)\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 146, in __call__\n",
      "    outputs = self._call(device, args)\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 153, in _call\n",
      "    ret = self._func(*args)\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/data_adapter.py\", line 519, in py_method\n",
      "    return [slice_array(inp) for inp in flat_inputs]\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/data_adapter.py\", line 519, in <listcomp>\n",
      "    return [slice_array(inp) for inp in flat_inputs]\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/data_adapter.py\", line 515, in slice_array\n",
      "    return training_utils.slice_arrays(\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/training_utils.py\", line 47, in slice_arrays\n",
      "    entries = [[x[i : i + 1] for i in indices] for x in arrays]\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/training_utils.py\", line 47, in <listcomp>\n",
      "    entries = [[x[i : i + 1] for i in indices] for x in arrays]\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/training_utils.py\", line 47, in <listcomp>\n",
      "    entries = [[x[i : i + 1] for i in indices] for x in arrays]\n",
      "\n",
      "TypeError: 'SparseTensor' object is not subscriptable\n",
      "\n",
      "\n",
      "2024-02-23 17:00:56.193353: W tensorflow/core/framework/op_kernel.cc:1827] INVALID_ARGUMENT: TypeError: 'SparseTensor' object is not subscriptable\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n",
      "    return func(device, token, args)\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 146, in __call__\n",
      "    outputs = self._call(device, args)\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 153, in _call\n",
      "    ret = self._func(*args)\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/data_adapter.py\", line 519, in py_method\n",
      "    return [slice_array(inp) for inp in flat_inputs]\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/data_adapter.py\", line 519, in <listcomp>\n",
      "    return [slice_array(inp) for inp in flat_inputs]\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/data_adapter.py\", line 515, in slice_array\n",
      "    return training_utils.slice_arrays(\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/training_utils.py\", line 47, in slice_arrays\n",
      "    entries = [[x[i : i + 1] for i in indices] for x in arrays]\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/training_utils.py\", line 47, in <listcomp>\n",
      "    entries = [[x[i : i + 1] for i in indices] for x in arrays]\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/training_utils.py\", line 47, in <listcomp>\n",
      "    entries = [[x[i : i + 1] for i in indices] for x in arrays]\n",
      "\n",
      "TypeError: 'SparseTensor' object is not subscriptable\n",
      "\n",
      "\n",
      "2024-02-23 17:00:56.193475: W tensorflow/core/framework/op_kernel.cc:1827] INVALID_ARGUMENT: TypeError: 'SparseTensor' object is not subscriptable\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n",
      "    return func(device, token, args)\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 146, in __call__\n",
      "    outputs = self._call(device, args)\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 153, in _call\n",
      "    ret = self._func(*args)\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/data_adapter.py\", line 519, in py_method\n",
      "    return [slice_array(inp) for inp in flat_inputs]\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/data_adapter.py\", line 519, in <listcomp>\n",
      "    return [slice_array(inp) for inp in flat_inputs]\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/data_adapter.py\", line 515, in slice_array\n",
      "    return training_utils.slice_arrays(\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/training_utils.py\", line 47, in slice_arrays\n",
      "    entries = [[x[i : i + 1] for i in indices] for x in arrays]\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/training_utils.py\", line 47, in <listcomp>\n",
      "    entries = [[x[i : i + 1] for i in indices] for x in arrays]\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/training_utils.py\", line 47, in <listcomp>\n",
      "    entries = [[x[i : i + 1] for i in indices] for x in arrays]\n",
      "\n",
      "TypeError: 'SparseTensor' object is not subscriptable\n",
      "\n",
      "\n",
      "2024-02-23 17:00:56.193524: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 5992278846186173564\n",
      "2024-02-23 17:00:56.193529: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 6550692849331734072\n",
      "2024-02-23 17:00:56.193584: W tensorflow/core/framework/op_kernel.cc:1827] INVALID_ARGUMENT: TypeError: 'SparseTensor' object is not subscriptable\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n",
      "    return func(device, token, args)\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 146, in __call__\n",
      "    outputs = self._call(device, args)\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 153, in _call\n",
      "    ret = self._func(*args)\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/data_adapter.py\", line 519, in py_method\n",
      "    return [slice_array(inp) for inp in flat_inputs]\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/data_adapter.py\", line 519, in <listcomp>\n",
      "    return [slice_array(inp) for inp in flat_inputs]\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/data_adapter.py\", line 515, in slice_array\n",
      "    return training_utils.slice_arrays(\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/training_utils.py\", line 47, in slice_arrays\n",
      "    entries = [[x[i : i + 1] for i in indices] for x in arrays]\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/training_utils.py\", line 47, in <listcomp>\n",
      "    entries = [[x[i : i + 1] for i in indices] for x in arrays]\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/training_utils.py\", line 47, in <listcomp>\n",
      "    entries = [[x[i : i + 1] for i in indices] for x in arrays]\n",
      "\n",
      "TypeError: 'SparseTensor' object is not subscriptable\n",
      "\n",
      "\n",
      "2024-02-23 17:00:56.193653: W tensorflow/core/framework/op_kernel.cc:1827] INVALID_ARGUMENT: TypeError: 'SparseTensor' object is not subscriptable\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n",
      "    return func(device, token, args)\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 146, in __call__\n",
      "    outputs = self._call(device, args)\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 153, in _call\n",
      "    ret = self._func(*args)\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/data_adapter.py\", line 519, in py_method\n",
      "    return [slice_array(inp) for inp in flat_inputs]\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/data_adapter.py\", line 519, in <listcomp>\n",
      "    return [slice_array(inp) for inp in flat_inputs]\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/data_adapter.py\", line 515, in slice_array\n",
      "    return training_utils.slice_arrays(\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/training_utils.py\", line 47, in slice_arrays\n",
      "    entries = [[x[i : i + 1] for i in indices] for x in arrays]\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/training_utils.py\", line 47, in <listcomp>\n",
      "    entries = [[x[i : i + 1] for i in indices] for x in arrays]\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/training_utils.py\", line 47, in <listcomp>\n",
      "    entries = [[x[i : i + 1] for i in indices] for x in arrays]\n",
      "\n",
      "TypeError: 'SparseTensor' object is not subscriptable\n",
      "\n",
      "\n",
      "2024-02-23 17:00:56.193987: W tensorflow/core/framework/op_kernel.cc:1827] INVALID_ARGUMENT: TypeError: 'SparseTensor' object is not subscriptable\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n",
      "    return func(device, token, args)\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 146, in __call__\n",
      "    outputs = self._call(device, args)\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 153, in _call\n",
      "    ret = self._func(*args)\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/data_adapter.py\", line 519, in py_method\n",
      "    return [slice_array(inp) for inp in flat_inputs]\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/data_adapter.py\", line 519, in <listcomp>\n",
      "    return [slice_array(inp) for inp in flat_inputs]\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/data_adapter.py\", line 515, in slice_array\n",
      "    return training_utils.slice_arrays(\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/training_utils.py\", line 47, in slice_arrays\n",
      "    entries = [[x[i : i + 1] for i in indices] for x in arrays]\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/training_utils.py\", line 47, in <listcomp>\n",
      "    entries = [[x[i : i + 1] for i in indices] for x in arrays]\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/training_utils.py\", line 47, in <listcomp>\n",
      "    entries = [[x[i : i + 1] for i in indices] for x in arrays]\n",
      "\n",
      "TypeError: 'SparseTensor' object is not subscriptable\n",
      "\n",
      "\n",
      "2024-02-23 17:00:56.194069: W tensorflow/core/framework/op_kernel.cc:1827] INVALID_ARGUMENT: TypeError: 'SparseTensor' object is not subscriptable\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n",
      "    return func(device, token, args)\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 146, in __call__\n",
      "    outputs = self._call(device, args)\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 153, in _call\n",
      "    ret = self._func(*args)\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/data_adapter.py\", line 519, in py_method\n",
      "    return [slice_array(inp) for inp in flat_inputs]\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/data_adapter.py\", line 519, in <listcomp>\n",
      "    return [slice_array(inp) for inp in flat_inputs]\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/data_adapter.py\", line 515, in slice_array\n",
      "    return training_utils.slice_arrays(\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/training_utils.py\", line 47, in slice_arrays\n",
      "    entries = [[x[i : i + 1] for i in indices] for x in arrays]\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/training_utils.py\", line 47, in <listcomp>\n",
      "    entries = [[x[i : i + 1] for i in indices] for x in arrays]\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/training_utils.py\", line 47, in <listcomp>\n",
      "    entries = [[x[i : i + 1] for i in indices] for x in arrays]\n",
      "\n",
      "TypeError: 'SparseTensor' object is not subscriptable\n",
      "\n",
      "\n",
      "2024-02-23 17:00:56.194118: W tensorflow/core/framework/op_kernel.cc:1827] INVALID_ARGUMENT: TypeError: 'SparseTensor' object is not subscriptable\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n",
      "    return func(device, token, args)\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 146, in __call__\n",
      "    outputs = self._call(device, args)\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 153, in _call\n",
      "    ret = self._func(*args)\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/data_adapter.py\", line 519, in py_method\n",
      "    return [slice_array(inp) for inp in flat_inputs]\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/data_adapter.py\", line 519, in <listcomp>\n",
      "    return [slice_array(inp) for inp in flat_inputs]\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/data_adapter.py\", line 515, in slice_array\n",
      "    return training_utils.slice_arrays(\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/training_utils.py\", line 47, in slice_arrays\n",
      "    entries = [[x[i : i + 1] for i in indices] for x in arrays]\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/training_utils.py\", line 47, in <listcomp>\n",
      "    entries = [[x[i : i + 1] for i in indices] for x in arrays]\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/training_utils.py\", line 47, in <listcomp>\n",
      "    entries = [[x[i : i + 1] for i in indices] for x in arrays]\n",
      "\n",
      "TypeError: 'SparseTensor' object is not subscriptable\n",
      "\n",
      "\n",
      "2024-02-23 17:00:56.194213: W tensorflow/core/framework/op_kernel.cc:1827] INVALID_ARGUMENT: TypeError: 'SparseTensor' object is not subscriptable\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n",
      "    return func(device, token, args)\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 146, in __call__\n",
      "    outputs = self._call(device, args)\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 153, in _call\n",
      "    ret = self._func(*args)\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/data_adapter.py\", line 519, in py_method\n",
      "    return [slice_array(inp) for inp in flat_inputs]\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/data_adapter.py\", line 519, in <listcomp>\n",
      "    return [slice_array(inp) for inp in flat_inputs]\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/data_adapter.py\", line 515, in slice_array\n",
      "    return training_utils.slice_arrays(\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/training_utils.py\", line 47, in slice_arrays\n",
      "    entries = [[x[i : i + 1] for i in indices] for x in arrays]\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/training_utils.py\", line 47, in <listcomp>\n",
      "    entries = [[x[i : i + 1] for i in indices] for x in arrays]\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/training_utils.py\", line 47, in <listcomp>\n",
      "    entries = [[x[i : i + 1] for i in indices] for x in arrays]\n",
      "\n",
      "TypeError: 'SparseTensor' object is not subscriptable\n",
      "\n",
      "\n",
      "2024-02-23 17:00:56.194394: W tensorflow/core/framework/op_kernel.cc:1827] INVALID_ARGUMENT: TypeError: 'SparseTensor' object is not subscriptable\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n",
      "    return func(device, token, args)\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 146, in __call__\n",
      "    outputs = self._call(device, args)\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 153, in _call\n",
      "    ret = self._func(*args)\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/data_adapter.py\", line 519, in py_method\n",
      "    return [slice_array(inp) for inp in flat_inputs]\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/data_adapter.py\", line 519, in <listcomp>\n",
      "    return [slice_array(inp) for inp in flat_inputs]\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/data_adapter.py\", line 515, in slice_array\n",
      "    return training_utils.slice_arrays(\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/training_utils.py\", line 47, in slice_arrays\n",
      "    entries = [[x[i : i + 1] for i in indices] for x in arrays]\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/training_utils.py\", line 47, in <listcomp>\n",
      "    entries = [[x[i : i + 1] for i in indices] for x in arrays]\n",
      "\n",
      "  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/training_utils.py\", line 47, in <listcomp>\n",
      "    entries = [[x[i : i + 1] for i in indices] for x in arrays]\n",
      "\n",
      "TypeError: 'SparseTensor' object is not subscriptable\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node EagerPyFunc defined at (most recent call last):\n<stack traces unavailable>\nDetected at node EagerPyFunc defined at (most recent call last):\n<stack traces unavailable>\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  TypeError: 'SparseTensor' object is not subscriptable\nTraceback (most recent call last):\n\n  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n    return func(device, token, args)\n\n  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 146, in __call__\n    outputs = self._call(device, args)\n\n  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 153, in _call\n    ret = self._func(*args)\n\n  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/data_adapter.py\", line 519, in py_method\n    return [slice_array(inp) for inp in flat_inputs]\n\n  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/data_adapter.py\", line 519, in <listcomp>\n    return [slice_array(inp) for inp in flat_inputs]\n\n  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/data_adapter.py\", line 515, in slice_array\n    return training_utils.slice_arrays(\n\n  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/training_utils.py\", line 47, in slice_arrays\n    entries = [[x[i : i + 1] for i in indices] for x in arrays]\n\n  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/training_utils.py\", line 47, in <listcomp>\n    entries = [[x[i : i + 1] for i in indices] for x in arrays]\n\n  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/training_utils.py\", line 47, in <listcomp>\n    entries = [[x[i : i + 1] for i in indices] for x in arrays]\n\nTypeError: 'SparseTensor' object is not subscriptable\n\n\n\t [[{{node EagerPyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[IteratorGetNext/_8]]\n  (1) INVALID_ARGUMENT:  TypeError: 'SparseTensor' object is not subscriptable\nTraceback (most recent call last):\n\n  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n    return func(device, token, args)\n\n  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 146, in __call__\n    outputs = self._call(device, args)\n\n  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 153, in _call\n    ret = self._func(*args)\n\n  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/data_adapter.py\", line 519, in py_method\n    return [slice_array(inp) for inp in flat_inputs]\n\n  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/data_adapter.py\", line 519, in <listcomp>\n    return [slice_array(inp) for inp in flat_inputs]\n\n  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/data_adapter.py\", line 515, in slice_array\n    return training_utils.slice_arrays(\n\n  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/training_utils.py\", line 47, in slice_arrays\n    entries = [[x[i : i + 1] for i in indices] for x in arrays]\n\n  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/training_utils.py\", line 47, in <listcomp>\n    entries = [[x[i : i + 1] for i in indices] for x in arrays]\n\n  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/training_utils.py\", line 47, in <listcomp>\n    entries = [[x[i : i + 1] for i in indices] for x in arrays]\n\nTypeError: 'SparseTensor' object is not subscriptable\n\n\n\t [[{{node EagerPyFunc}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_227791]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 55\u001b[0m\n\u001b[1;32m     50\u001b[0m model \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mModel(inputs\u001b[38;5;241m=\u001b[39minputs, outputs\u001b[38;5;241m=\u001b[39moutputs, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment_model\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     51\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     52\u001b[0m               loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     53\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 55\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node EagerPyFunc defined at (most recent call last):\n<stack traces unavailable>\nDetected at node EagerPyFunc defined at (most recent call last):\n<stack traces unavailable>\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  TypeError: 'SparseTensor' object is not subscriptable\nTraceback (most recent call last):\n\n  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n    return func(device, token, args)\n\n  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 146, in __call__\n    outputs = self._call(device, args)\n\n  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 153, in _call\n    ret = self._func(*args)\n\n  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/data_adapter.py\", line 519, in py_method\n    return [slice_array(inp) for inp in flat_inputs]\n\n  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/data_adapter.py\", line 519, in <listcomp>\n    return [slice_array(inp) for inp in flat_inputs]\n\n  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/data_adapter.py\", line 515, in slice_array\n    return training_utils.slice_arrays(\n\n  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/training_utils.py\", line 47, in slice_arrays\n    entries = [[x[i : i + 1] for i in indices] for x in arrays]\n\n  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/training_utils.py\", line 47, in <listcomp>\n    entries = [[x[i : i + 1] for i in indices] for x in arrays]\n\n  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/training_utils.py\", line 47, in <listcomp>\n    entries = [[x[i : i + 1] for i in indices] for x in arrays]\n\nTypeError: 'SparseTensor' object is not subscriptable\n\n\n\t [[{{node EagerPyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[IteratorGetNext/_8]]\n  (1) INVALID_ARGUMENT:  TypeError: 'SparseTensor' object is not subscriptable\nTraceback (most recent call last):\n\n  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n    return func(device, token, args)\n\n  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 146, in __call__\n    outputs = self._call(device, args)\n\n  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 153, in _call\n    ret = self._func(*args)\n\n  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/data_adapter.py\", line 519, in py_method\n    return [slice_array(inp) for inp in flat_inputs]\n\n  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/data_adapter.py\", line 519, in <listcomp>\n    return [slice_array(inp) for inp in flat_inputs]\n\n  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/data_adapter.py\", line 515, in slice_array\n    return training_utils.slice_arrays(\n\n  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/training_utils.py\", line 47, in slice_arrays\n    entries = [[x[i : i + 1] for i in indices] for x in arrays]\n\n  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/training_utils.py\", line 47, in <listcomp>\n    entries = [[x[i : i + 1] for i in indices] for x in arrays]\n\n  File \"/Users/alexismena/Documents/Deep_Learning_Projects/TensorFlow_Basics/.venv/lib/python3.10/site-packages/keras/src/engine/training_utils.py\", line 47, in <listcomp>\n    entries = [[x[i : i + 1] for i in indices] for x in arrays]\n\nTypeError: 'SparseTensor' object is not subscriptable\n\n\n\t [[{{node EagerPyFunc}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_227791]"
     ]
    }
   ],
   "source": [
    "# Iter 3\n",
    "# Read dataset\n",
    "sw = stopwords.words('english')\n",
    "df_train = pd.read_csv('../data/01_IMDB_Train.csv')\n",
    "df_val = pd.read_csv('../data/01_IMDB_Valid.csv')\n",
    "df_test = pd.read_csv('../data/01_IMDB_Test.csv')\n",
    "df_train.info()\n",
    "# Clean data\n",
    "def clean_text_fn(dataframe):\n",
    "    dataframe['text'] = dataframe['text'].apply(lambda x: x.lower())\n",
    "    dataframe['text'] = dataframe['text'].str.replace(r'(<.*?>)','',regex=True)\n",
    "    dataframe['text'] = dataframe['text'].str.replace(r'''['!,.;]''', '', regex=True)\n",
    "    dataframe['text'] = dataframe['text'].str.replace(r'[?]', ' question_mark ', regex=True)\n",
    "    dataframe['text'] = dataframe['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (sw)]))\n",
    "    dataframe['text'] = dataframe['text'].str.strip()\n",
    "    return dataframe\n",
    "train_ds = clean_text_fn(df_train)\n",
    "val_ds = clean_text_fn(df_val)\n",
    "test_ds = clean_text_fn(df_test)\n",
    "# Tokenize data\n",
    "countvectorizer = CountVectorizer()\n",
    "countvectorizer.fit(train_ds['text'])\n",
    "X_train = countvectorizer.transform(train_ds['text'])\n",
    "X_val = countvectorizer.transform(val_ds['text'])\n",
    "X_test = countvectorizer.transform(test_ds['text'])\n",
    "\n",
    "# tokenizer = Tokenizer(num_words=20000, oov_token='<OOV>')\n",
    "# tokenizer.fit_on_texts(train_ds['text'])\n",
    "# word_index = tokenizer.word_index\n",
    "# def tokenize_and_pad(dataframe):\n",
    "#     sequences = tokenizer.texts_to_sequences(dataframe['text'])\n",
    "#     padded_sequences = pad_sequences(sequences, maxlen=200, padding='post')\n",
    "#     return padded_sequences\n",
    "# X_train = tokenize_and_pad(train_ds)\n",
    "# X_val = tokenize_and_pad(val_ds)\n",
    "# X_test = tokenize_and_pad(test_ds)\n",
    "\n",
    "\n",
    "y_train = train_ds['label']\n",
    "y_val = val_ds['label']\n",
    "y_test = test_ds['label']\n",
    "# Build model\n",
    "inputs = keras.Input(shape=(X_train.shape[1],))\n",
    "x = layers.Dense(64, activation='relu')(inputs)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs, name='sentiment_model')\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_val,y_val), epochs=10, batch_size=32, validation_batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>grew (b 1965) watching loving thunderbirds mat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>put movie dvd player sat coke chips expectatio...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>people know particular time past like feel nee...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>even though great interest biblical movies bor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>im die hard dads army fan nothing ever change ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>\"western union\" something forgotten classic we...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>movie incredible piece work explores every noo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>wife watched movie plan visit sicily stromboli...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>first watched flatliners amazed necessary feat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>would film good gross estimated $95000000 awar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "0      grew (b 1965) watching loving thunderbirds mat...      0\n",
       "1      put movie dvd player sat coke chips expectatio...      0\n",
       "2      people know particular time past like feel nee...      0\n",
       "3      even though great interest biblical movies bor...      0\n",
       "4      im die hard dads army fan nothing ever change ...      1\n",
       "...                                                  ...    ...\n",
       "39995  \"western union\" something forgotten classic we...      1\n",
       "39996  movie incredible piece work explores every noo...      1\n",
       "39997  wife watched movie plan visit sicily stromboli...      0\n",
       "39998  first watched flatliners amazed necessary feat...      1\n",
       "39999  would film good gross estimated $95000000 awar...      1\n",
       "\n",
       "[40000 rows x 2 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iter 4\n",
    "# Read dataset\n",
    "sw = stopwords.words('english')\n",
    "df_train = pd.read_csv('../data/01_IMDB_Train.csv')\n",
    "df_val = pd.read_csv('../data/01_IMDB_Valid.csv')\n",
    "df_test = pd.read_csv('../data/01_IMDB_Test.csv')\n",
    "df_train.info()\n",
    "\n",
    "# Clean data\n",
    "def clean_text_fn(dataframe):\n",
    "    dataframe['text'] = dataframe['text'].apply(lambda x: x.lower())\n",
    "    dataframe['text'] = dataframe['text'].str.replace(r'(<.*?>)','',regex=True)\n",
    "    dataframe['text'] = dataframe['text'].str.replace(r'''['!,.;]''', '', regex=True)\n",
    "    dataframe['text'] = dataframe['text'].str.replace(r'[?]', ' question_mark ', regex=True)\n",
    "    dataframe['text'] = dataframe['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (sw)]))\n",
    "    dataframe['text'] = dataframe['text'].str.strip()\n",
    "    return dataframe\n",
    "train_ds = clean_text_fn(df_train)\n",
    "val_ds = clean_text_fn(df_val)\n",
    "test_ds = clean_text_fn(df_test)\n",
    "\n",
    "# Tokenize, pad\n",
    "tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40000 entries, 0 to 39999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    40000 non-null  object\n",
      " 1   label   40000 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 625.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# Iter 5: Damn, it's been tedious this...\n",
    "# Read dataset\n",
    "sw = stopwords.words('english')\n",
    "df_train = pd.read_csv('../data/01_IMDB_Train.csv')\n",
    "df_val = pd.read_csv('../data/01_IMDB_Valid.csv')\n",
    "df_test = pd.read_csv('../data/01_IMDB_Test.csv')\n",
    "df_train.info()\n",
    "\n",
    "# Create tensorflow dataset\n",
    "def make_data(dataset):\n",
    "    return tf.data.Dataset.from_tensor_slices(\n",
    "        (\n",
    "            {'text':dataset['text']},\n",
    "            {'label':dataset['label']}\n",
    "        )\n",
    "    )\n",
    "train = make_data(df_train).batch(32)\n",
    "val = make_data(df_val).batch(32)\n",
    "test = make_data(df_test).batch(32)\n",
    "\n",
    "# Vectorize datat\n",
    "def custom_standardization_fn(string_tensor):\n",
    "    stripped_string = tf.strings.strip(string_tensor)\n",
    "    lowercase_string = tf.strings.lower(stripped_string)\n",
    "    tagless_string = tf.strings.regex_replace(lowercase_string, '<.*?>', '')\n",
    "    single_space_string = tf.strings.regex_replace(tagless_string, '\\s+',' ')\n",
    "    comma_space_string = tf.strings.regex_replace(single_space_string, '\\s,\\s',', ')\n",
    "    simple_vowel_a_string = tf.strings.regex_replace(comma_space_string, 'a{3,}', 'a')\n",
    "    simple_vowel_e_string = tf.strings.regex_replace(simple_vowel_a_string, 'e{3,}', 'e')\n",
    "    simple_vowel_i_string = tf.strings.regex_replace(simple_vowel_e_string, 'i{3, }', 'i')\n",
    "    simple_vowel_o_string = tf.strings.regex_replace(simple_vowel_i_string, 'o{3, }', 'o')\n",
    "    simple_vowel_u_string = tf.strings.regex_replace(simple_vowel_o_string, 'u{3, }', 'u')\n",
    "    stripped_string_again = tf.strings.strip(simple_vowel_u_string)\n",
    "    return tf.strings.regex_replace(stripped_string_again,\n",
    "                                    f\"[{re.escape(string.punctuation)}]\",'')\n",
    "\n",
    "def create_vectorize_layer(train, feature):\n",
    "    vectorize_layer = TextVectorization(\n",
    "        standardize=custom_standardization_fn,\n",
    "        max_tokens=10000,\n",
    "        output_mode='int',\n",
    "        output_sequence_length=500\n",
    "    )\n",
    "    vectorize_layer.adapt(train.map(lambda x, y: x[feature]))\n",
    "    return vectorize_layer\n",
    "\n",
    "vectorize_text = create_vectorize_layer(train, 'text')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_df\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_df' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>grew (b. 1965) watching loving thunderbirds. m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>put movie dvd player, sat coke chips, expectat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>people know particular time past like feel nee...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>even though great interest biblical movies, bo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>im die hard dads army fan nothing ever change ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>\"western union\" something forgotten classic we...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>movie incredible piece work. explores every no...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>wife watched movie plan visit sicily stromboli...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>first watched flatliners, amazed. necessary fe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>would film good, gross estimated $95,000,000 a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "0      grew (b. 1965) watching loving thunderbirds. m...      0\n",
       "1      put movie dvd player, sat coke chips, expectat...      0\n",
       "2      people know particular time past like feel nee...      0\n",
       "3      even though great interest biblical movies, bo...      0\n",
       "4      im die hard dads army fan nothing ever change ...      1\n",
       "...                                                  ...    ...\n",
       "39995  \"western union\" something forgotten classic we...      1\n",
       "39996  movie incredible piece work. explores every no...      1\n",
       "39997  wife watched movie plan visit sicily stromboli...      0\n",
       "39998  first watched flatliners, amazed. necessary fe...      1\n",
       "39999  would film good, gross estimated $95,000,000 a...      1\n",
       "\n",
       "[40000 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.3 Preprocess data in order to avoid html tags and show result\n",
    "# df_interim = df_raw.copy()\n",
    "# # Get original lenght of words\n",
    "# df_interim['original_len'] = df_interim['review'].apply(lambda x: len(x.split(' '))) \n",
    "# # Supress html tags\n",
    "# df_interim['user_review'] = df_interim['review'].str.replace(r'(<.*?>)','',regex=True)\n",
    "# # In case of many white spaces, replace with only one white space\n",
    "# df_interim['user_review'] = df_interim['user_review'].str.replace(r'\\s+',' ',regex=True)\n",
    "# # In case of a space followed by a comma, replace with a comma followed by a space\n",
    "# df_interim['user_review'] = df_interim['user_review'].str.replace(r'\\s,\\s',', ',regex=True)\n",
    "# # Replace backslashes\n",
    "# df_interim['user_review'] = df_interim['user_review'].str.replace(r'\\\\','',regex=True)\n",
    "# # In case of three or more consecutive letters, replace with only two or less consecutive letters\n",
    "# df_interim['user_review'] = df_interim['user_review'].str.replace(r'([a-zA-Z])\\1{2,}', r'\\1', regex=True)\n",
    "# # Strip white spaces at the beginning and at the end of the review\n",
    "# df_interim['user_review'] = df_interim['user_review'].str.strip()\n",
    "# # Convert labels into integers\n",
    "# df_interim['label'] = df_interim['sentiment'].apply(lambda x: 1 if x == 'positive' else 0)\n",
    "# # Drop duplicates\n",
    "# df_interim = df_interim.drop_duplicates()\n",
    "# # There's a particular repeated row\n",
    "# df_interim = df_interim.drop([44855],axis=0)\n",
    "# # Apply custom function to split long sentences into more \n",
    "# df_interim['reviews'] = df_interim['user_review'].apply(lambda x: sentence_fixed_split(x,1000))\n",
    "# df_interim = df_interim.explode('reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3. Create the deep learning model \n",
    "# 3.1 Prepare data to encode dependent variable as a numeric\n",
    "train_df['sentiment'] = train_df['sentiment'].apply(lambda x: 1 if x == 'positive' else 0)\n",
    "val_df['sentiment'] = val_df['sentiment'].apply(lambda x: 1 if x == 'positive' else 0)\n",
    "test_df['sentiment'] = test_df['sentiment'].apply(lambda x: 1 if x == 'positive' else 0)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df = val_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((\n",
    "    tf.cast(train_df['review'], tf.string),\n",
    "    tf.cast(train_df['sentiment'], tf.int32)\n",
    "))\n",
    "\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((\n",
    "    tf.cast(val_df['review'], tf.string),\n",
    "    tf.cast(val_df['sentiment'], tf.int32)\n",
    "))\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((\n",
    "    tf.cast(test_df['review'], tf.string),\n",
    "    tf.cast(test_df['sentiment'], tf.int32)\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2 Create custom functions for strings on the model pipeline\n",
    "def custom_standardization_fn(string_tensor):\n",
    "    stripped_string = tf.strings.strip(string_tensor)\n",
    "    lowercase_string = tf.strings.lower(stripped_string)\n",
    "    tagless_string = tf.strings.regex_replace(lowercase_string, '<.*?>', '')\n",
    "    single_space_string = tf.strings.regex_replace(tagless_string, '\\s+',' ')\n",
    "    comma_space_string = tf.strings.regex_replace(single_space_string, '\\s,\\s',', ')\n",
    "    simple_vowel_a_string = tf.strings.regex_replace(comma_space_string, 'a{3,}', 'a')\n",
    "    simple_vowel_e_string = tf.strings.regex_replace(simple_vowel_a_string, 'e{3,}', 'e')\n",
    "    simple_vowel_i_string = tf.strings.regex_replace(simple_vowel_e_string, 'i{3, }', 'i')\n",
    "    simple_vowel_o_string = tf.strings.regex_replace(simple_vowel_i_string, 'o{3, }', 'o')\n",
    "    simple_vowel_u_string = tf.strings.regex_replace(simple_vowel_o_string, 'u{3, }', 'u')\n",
    "    stripped_string_again = tf.strings.strip(simple_vowel_u_string)\n",
    "    return tf.strings.regex_replace(stripped_string_again,\n",
    "                                    f\"[{re.escape(string.punctuation)}]\",'')\n",
    "    \n",
    "def custom_split_fn(string_tensor):\n",
    "    return tf.strings.split(string_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.3 Create the text vectorizer and apply to the data splits\n",
    "MAX_VOCAB = 20000\n",
    "MAX_LENGTH = 500\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "text_vectorizer = TextVectorization(\n",
    "    max_tokens=MAX_VOCAB,\n",
    "    standardize=custom_standardization_fn,\n",
    "    split=custom_split_fn,\n",
    "    output_mode='multi_hot'\n",
    ")\n",
    "\n",
    "text_vectorizer.adapt(train_df.review.values)\n",
    "X_train = text_vectorizer(train_df.review.values)\n",
    "X_val = text_vectorizer(val_df.review.values)\n",
    "X_test = text_vectorizer(test_df.review.values)\n",
    "y_train = tf.convert_to_tensor(train_df.sentiment.values)\n",
    "y_val = tf.convert_to_tensor(val_df.sentiment.values)\n",
    "y_test = tf.convert_to_tensor(test_df.sentiment.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = text_vectorizer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(max_tokens=MAX_VOCAB, hidden_dim=16):\n",
    "    inputs = keras.Input(shape=(max_tokens,))\n",
    "    x = layers.Dense(hidden_dim, activation='relu')(inputs)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=X_train,\n",
    "          y=y_train,\n",
    "          epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Embedding, Dense, GlobalAveragePooling1D\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the IMDB dataset from CSV\n",
    "data_path = '../data/01_IMDB_Dataset_HuggingFace.csv'  # Replace with the actual path\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Preprocess the data\n",
    "max_length = 256\n",
    "X = df['review'].values\n",
    "y = df['sentiment'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Tokenize and pad sequences\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train, maxlen=max_length)\n",
    "X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test, maxlen=max_length)\n",
    "\n",
    "# Define the model architecture\n",
    "input_layer = Input(shape=(max_length,))\n",
    "embedding_layer = Embedding(input_dim=10000, output_dim=16)(input_layer)\n",
    "average_pooling_layer = GlobalAveragePooling1D()(embedding_layer)\n",
    "dense_layer = Dense(16, activation='relu')(average_pooling_layer)\n",
    "output_layer = Dense(1, activation='sigmoid')(dense_layer)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate on test data\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {test_accuracy:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
